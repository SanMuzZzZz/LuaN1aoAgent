# ============================================================================
# LLM API 配置
# ============================================================================

# 必需: LLM服务的API密钥
LLM_API_KEY=your_api_key_here

# 可选: LLM API基础URL
LLM_API_BASE_URL=https://api.openai.com/v1

# 可选: 备用API密钥（用于处理限流）
LLM_FALLBACK_API_KEY=your_fallback_api_key_here

# ============================================================================
# LLM 提供商配置
# ============================================================================

# LLM提供商: "openai" 或 "anthropic"
LLM_PROVIDER=openai

# OpenAI模型配置
LLM_DEFAULT_MODEL=gpt-4o-mini
LLM_PLANNER_MODEL=gpt-4o-mini
LLM_EXECUTOR_MODEL=gpt-4o-mini
LLM_REFLECTOR_MODEL=gpt-4o-mini
LLM_EXPERT_ANALYSIS_MODEL=gpt-4o

# Anthropic API配置（如使用Claude）
ANTHROPIC_API_BASE_URL=https://api.anthropic.com/v1/messages
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_FALLBACK_API_KEY=your_anthropic_fallback_key_here
ANTHROPIC_VERSION=2023-06-01

# Anthropic模型配置
ANTHROPIC_DEFAULT_MODEL=claude-sonnet-4-5
ANTHROPIC_PLANNER_MODEL=claude-sonnet-4-5
ANTHROPIC_EXECUTOR_MODEL=claude-sonnet-4-5
ANTHROPIC_REFLECTOR_MODEL=claude-sonnet-4-5
ANTHROPIC_EXPERT_MODEL=claude-sonnet-4-5

# ============================================================================
# 核心场景配置 (Scenario Configuration)
# ============================================================================

# 运行场景模式: "general" (通用模式,默认) 或 "ctf" (CTF模式,会启用特定Prompt优化)
SCENARIO_MODE=general

# 可选值: "simple" (简单模式,只输出最终结果) 或 "default" (默认模式) 或 "debug" (调试模式,会输出更多中间结果)
OUTPUT_MODE=simple

# ============================================================================
# LLM高级配置
# ============================================================================

# 是否启用OpenAI兼容接口的extra_body字段，用于传递供应商自定义参数（如思考模式thinking）
LLM_EXTRA_BODY_ENABLED=false

# 为默认角色配置是否开启“思考模式”（extra_body.thinking）。可选值："off", "hidden", "visible"
LLM_DEFAULT_THINKING=off

# ============================================================================
# RAG 知识检索配置
# ============================================================================

# 知识服务Host
KNOWLEDGE_SERVICE_HOST=127.0.0.1

# 知识服务端口
KNOWLEDGE_SERVICE_PORT=8081

# 检索片段长度（字符数）
RAG_SNIPPET_LEN=800

# 检索结果数量
RAG_TOP_K=5

# ============================================================================
# Web 可视化配置
# ============================================================================

# Web服务主机地址
WEB_HOST=127.0.0.1

# Web服务端口
WEB_PORT=8000

# ============================================================================
# 执行器配置
# ============================================================================

# 执行器最大步数
EXECUTOR_MAX_STEPS=12

# 消息历史压缩阈值
EXECUTOR_MESSAGE_COMPRESS_THRESHOLD=12

# Token数量压缩阈值
EXECUTOR_TOKEN_COMPRESS_THRESHOLD=80000

# 无新产出物的耐心值（连续多少步无产出则终止）
EXECUTOR_NO_ARTIFACTS_PATIENCE=10

# 失败阈值（连续失败多少次触发策略切换）
EXECUTOR_FAILURE_THRESHOLD=3

# 上下文压缩时保留的最近消息数
EXECUTOR_RECENT_MESSAGES_KEEP=6

# 最小压缩消息阈值
EXECUTOR_MIN_COMPRESS_MESSAGES=5

# 执行轮次压缩间隔
EXECUTOR_COMPRESS_INTERVAL=5

# 执行轮次压缩时的消息数阈值
EXECUTOR_COMPRESS_INTERVAL_MSG_THRESHOLD=8

# 工具调用超时时间（秒）
EXECUTOR_TOOL_TIMEOUT=120

# 执行器观察结果的最大长度（字符），超过此长度将被截断
EXECUTOR_MAX_OUTPUT_LENGTH=50000

# ============================================================================
# 上下文管理配置
# ============================================================================

# 规划历史保留窗口大小
PLANNER_HISTORY_WINDOW=15

# 反思日志保留窗口大小
REFLECTOR_HISTORY_WINDOW=15

# ============================================================================
# 人工协同 (HITL) 配置
# ============================================================================

# 是否开启人工介入模式
# 开启后，Agent在生成规划后会暂停，等待Web UI或CLI的人工审批
HUMAN_IN_THE_LOOP=false

# ============================================================================
# 温度参数配置
# ============================================================================

# 各模块的temperature参数（控制输出随机性，0.0-1.0）
LLM_PLANNER_TEMPERATURE=0.1
LLM_EXECUTOR_TEMPERATURE=0.1
LLM_REFLECTOR_TEMPERATURE=0.0
LLM_EXPERT_ANALYSIS_TEMPERATURE=0.0

# ============================================================================
# 高级配置（一般不需要修改）
# ============================================================================

# LLM请求超时时间（秒）
LLM_TIMEOUT=60

# LLM最大重试次数
LLM_MAX_RETRIES=3

# 日志级别: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO