#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""LuaN1ao Agent - åŸºäºå¤§æ¨¡å‹çš„è‡ªä¸»æ¸—é€æµ‹è¯•ç³»ç»Ÿä¸»æ§å…¥å£.

æœ¬æ¨¡å—å®ç°äº†P-E-R (Planner-Executor-Reflector) æ¶æ„çš„æ ¸å¿ƒæ§åˆ¶é€»è¾‘,
é€šè¿‡åè°ƒè§„åˆ’å™¨ã€æ‰§è¡Œå™¨å’Œåæ€å™¨ä¸‰ä¸ªç»„ä»¶,å®ç°è‡ªåŠ¨åŒ–çš„æ¸—é€æµ‹è¯•ä»»åŠ¡æ‰§è¡Œã€‚

ä¸»è¦åŠŸèƒ½:
    - ä»»åŠ¡åˆå§‹åŒ–ä¸é…ç½®ç®¡ç†
    - P-E-Rå¾ªç¯æ§åˆ¶ä¸åè°ƒ
    - å›¾è°±ç®¡ç†ä¸çŠ¶æ€è¿½è¸ª
    - æŒ‡æ ‡æ”¶é›†ä¸æ—¥å¿—è®°å½•
    - Webå¯è§†åŒ–æœåŠ¡(å¯é€‰)

å…¸å‹ç”¨æ³•:
    python agent.py --goal "æµ‹è¯•ç›®æ ‡åº”ç”¨çš„å®‰å…¨æ€§" --task-name "web_pentest"

ä½œè€…: LuaN1ao Team
è®¸å¯: MIT License
"""

# agent.py
# LuaN1ao Agent ä¸»æ§å…¥å£ (P-E-R æ¶æ„)
import json
import os
import sys
import uuid
import time
import asyncio
import argparse
import tempfile
from collections import defaultdict
from datetime import datetime
from typing import List, Dict, Any, Optional
import httpx
import subprocess
import psutil

from rich.console import Console
from rich.panel import Panel

from core.console import set_console, init_console_with_file, console_proxy as console
from llm.llm_client import LLMClient
from tools.mcp_client import initialize_sessions, close_async_sessions
from core.graph_manager import GraphManager
from core.planner import Planner
from core.reflector import Reflector
from core.executor import run_executor_cycle
from core.data_contracts import PlannerContext, ReflectorContext
from tools import mcp_service
from core.tool_manager import tool_manager
from core.intervention import intervention_manager
from conf.config import (
    PLANNER_HISTORY_WINDOW,
    REFLECTOR_HISTORY_WINDOW,
    WEB_PORT as DEFAULT_WEB_PORT,
    KNOWLEDGE_SERVICE_PORT,
    KNOWLEDGE_SERVICE_URL,
    KNOWLEDGE_SERVICE_HOST,
    OUTPUT_MODE,
    HUMAN_IN_THE_LOOP
)
from core.events import broker
try:
    from web.server import register_graph
except Exception:
    register_graph = None

from core.console import sanitize_for_rich

def generate_task_id() -> str:
    """
    ç”Ÿæˆå”¯ä¸€ä»»åŠ¡ID
    
    Returns:
        æ ¼å¼ä¸º "task_{timestamp}_{uuid_prefix}" çš„å”¯ä¸€ä»»åŠ¡æ ‡è¯†ç¬¦
    """
    return f"task_{int(time.time())}_{str(uuid.uuid4())[:8]}"

# å…¨å±€çŸ¥è¯†æœåŠ¡çŠ¶æ€ç®¡ç†
_KNOWLEDGE_SERVICE_PID = None
_KNOWLEDGE_SERVICE_LOCK = asyncio.Lock()

async def check_knowledge_service_health(console: Console) -> bool:
    """æ£€æŸ¥çŸ¥è¯†æœåŠ¡æ˜¯å¦è¿è¡Œå¹¶ä¸”å¥åº·ã€‚"""
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(f"{KNOWLEDGE_SERVICE_URL}/health", timeout=2)
            if response.status_code == 200 and response.json().get("status") == "healthy":
                return True
            else:
                console.print(f"[bold yellow]âš ï¸ çŸ¥è¯†æœåŠ¡å“åº”ä¸å¥åº·: {response.status_code} - {response.text}[/bold yellow]")
                return False
    except httpx.RequestError as e:
        console.print(f"[bold red]âŒ æ— æ³•è¿æ¥åˆ°çŸ¥è¯†æœåŠ¡: {e}[/bold red]")
        return False

async def ensure_knowledge_service(console: Console):
    """ç¡®ä¿çŸ¥è¯†æœåŠ¡è¿è¡Œï¼ˆå…¨å±€å•ä¾‹æ¨¡å¼ï¼‰"""
    global _KNOWLEDGE_SERVICE_PID

    async with _KNOWLEDGE_SERVICE_LOCK:
        # æ£€æŸ¥æœåŠ¡æ˜¯å¦å·²ç»å¥åº·è¿è¡Œ
        if await check_knowledge_service_health(console):
            console.print("[bold green]âœ… çŸ¥è¯†æœåŠ¡å·²è¿è¡Œå¹¶å¥åº·ã€‚[/bold green]")
            return True

        # æ£€æŸ¥å…¨å±€æœåŠ¡PIDæ˜¯å¦æœ‰æ•ˆ
        if _KNOWLEDGE_SERVICE_PID:
            if psutil.pid_exists(_KNOWLEDGE_SERVICE_PID):
                console.print(f"[dim]çŸ¥è¯†æœåŠ¡è¿›ç¨‹ {_KNOWLEDGE_SERVICE_PID} å­˜åœ¨ä½†æœªå“åº”ï¼Œå°è¯•é‡å¯...[/dim]")
            else:
                _KNOWLEDGE_SERVICE_PID = None

        console.print("[bold blue]ğŸš€ å¯åŠ¨çŸ¥è¯†æœåŠ¡...[/bold blue]")

        # æ£€æŸ¥ç«¯å£å ç”¨ï¼ˆåªæ¸…ç†éå½“å‰è¿›ç¨‹ç»„çš„è¿›ç¨‹ï¼‰
        import socket
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        port_in_use = sock.connect_ex((KNOWLEDGE_SERVICE_HOST, KNOWLEDGE_SERVICE_PORT)) == 0
        sock.close()

        if port_in_use:
            console.print(f"[bold yellow]âš ï¸ ç«¯å£ {KNOWLEDGE_SERVICE_PORT} å·²è¢«å ç”¨ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºæŒä¹…åŒ–çŸ¥è¯†æœåŠ¡...[/bold yellow]")

            # æ£€æŸ¥ç«¯å£å ç”¨æ˜¯å¦ä¸ºçŸ¥è¯†æœåŠ¡è¿›ç¨‹
            try:
                for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                    try:
                        for conn in proc.connections(kind='inet'):
                            if conn.laddr.port == KNOWLEDGE_SERVICE_PORT:
                                cmdline = proc.info['cmdline']
                                if cmdline and "uvicorn" in " ".join(cmdline) and "knowledge_service" in " ".join(cmdline):
                                    console.print(f"[bold green]âœ… æ£€æµ‹åˆ°æŒä¹…åŒ–çŸ¥è¯†æœåŠ¡æ­£åœ¨è¿è¡Œ (PID: {proc.info['pid']})[/bold green]")
                                    return True
                                else:
                                    console.print(f"[dim]ç«¯å£è¢«éçŸ¥è¯†æœåŠ¡è¿›ç¨‹å ç”¨ PID: {proc.info['pid']}[/dim]")
                    except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                        pass
            except Exception as e:
                console.print(f"[dim]æ£€æŸ¥ç«¯å£å ç”¨è¿›ç¨‹æ—¶å‡ºé”™: {e}[/dim]")

        # å¯åŠ¨æœåŠ¡
        command = [
            sys.executable, "-m", "uvicorn", "rag.knowledge_service:app",
            "--host", "0.0.0.0", "--port", str(KNOWLEDGE_SERVICE_PORT)
        ]

        try:
            # ä½¿ç”¨ start_new_session=True æ›¿ä»£ preexec_fn=os.setsid ä»¥æ”¯æŒæ›´å¤šå¹³å°
            process = subprocess.Popen(command, start_new_session=True)
            _KNOWLEDGE_SERVICE_PID = process.pid
            console.print(f"[bold green]çŸ¥è¯†æœåŠ¡å·²åœ¨åå°å¯åŠ¨ (PID: {process.pid})ã€‚[/bold green]")

            # ç­‰å¾…æœåŠ¡å¥åº·æ£€æŸ¥ï¼ˆå¸¦è¶…æ—¶ï¼‰
            for i in range(15):  # æœ€å¤šç­‰å¾…30ç§’
                console.print(f"[dim]ç­‰å¾…çŸ¥è¯†æœåŠ¡å¯åŠ¨ ({i+1}/15)...[/dim]")
                if await check_knowledge_service_health(console):
                    console.print("[bold green]âœ… çŸ¥è¯†æœåŠ¡å·²æˆåŠŸå¯åŠ¨å¹¶å¥åº·ã€‚[/bold green]")
                    return True
                await asyncio.sleep(2)

            console.print("[bold red]âŒ çŸ¥è¯†æœåŠ¡å¯åŠ¨è¶…æ—¶ã€‚[/bold red]")
            return False

        except Exception as e:
            console.print(f"[bold red]âŒ çŸ¥è¯†æœåŠ¡å¯åŠ¨å¤±è´¥: {e}[/bold red]")
            return False

def _aggregate_intelligence(completed_reflections: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
    """
    æ±‡æ€»å¤šä¸ªåæ€å™¨è¾“å‡ºä¸ºæƒ…æŠ¥æ‘˜è¦.
    
    å°†å¤šä¸ªå­ä»»åŠ¡çš„åæ€ç»“æœæ±‡æ€»ä¸ºç»Ÿä¸€çš„æƒ…æŠ¥æ‘˜è¦ï¼Œä¼˜å…ˆå¤„ç†å·²è¾¾æˆç›®æ ‡çš„çŠ¶æ€
    å’Œç›®æ ‡äº§ç‰©ç±»å‹çš„artifactsã€‚
    
    Args:
        completed_reflections: å·²å®Œæˆçš„åæ€ç»“æœå­—å…¸ï¼Œkeyä¸ºå­ä»»åŠ¡IDï¼Œvalueä¸ºåæ€è¾“å‡º
        
    Returns:
        Dict[str, Any]: æ±‡æ€»çš„æƒ…æŠ¥æ‘˜è¦ï¼ŒåŒ…å«findingsã€audit_resultã€artifactsç­‰å­—æ®µ
    """
    all_findings = []
    all_artifacts = []
    all_insights = []

    # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•åæ€ç»“æœæ ‡è®°äº† GOAL_ACHIEVED
    goal_achieved = False
    aggregated_completion_check = f'æ±‡æ€»äº† {len(completed_reflections)} ä¸ªä»»åŠ¡çš„å®¡è®¡ç»“æœ'
    for subtask_id, reflection in completed_reflections.items():
        # ä» reflection æå–æ‰€éœ€å­—æ®µ
        audit_result = reflection.get('audit_result', {})
        if audit_result.get('status') == 'GOAL_ACHIEVED':
            goal_achievement_reason = audit_result.get('completion_check', 'Unknown reason for GOAL_ACHIEVED')
            console.print(
                f"ğŸ” Aggregator: æ£€æµ‹åˆ°å­ä»»åŠ¡ {subtask_id} æŠ¥å‘Š GOAL_ACHIEVED: {goal_achievement_reason}",
                style="bold green"
            )
            goal_achieved = True
            aggregated_completion_check = goal_achievement_reason

        # æå– key_findings
        findings = reflection.get('key_findings', [])
        all_findings.extend(findings)

        # æå– validated_nodes
        nodes = reflection.get('validated_nodes', [])
        all_artifacts.extend(nodes)

        # æå– insight
        insight = reflection.get('insight')
        if insight:
            all_insights.append(insight)

    # æ„å»ºæ±‡æ€»çš„æƒ…æŠ¥æ‘˜è¦
    aggregated_status = 'GOAL_ACHIEVED' if goal_achieved else 'AGGREGATED'
    intelligence_summary = {
        'findings': all_findings,
        'audit_result': {
            'status': aggregated_status,
            'completion_check': aggregated_completion_check
        },
        'artifacts': all_artifacts,
        'insight': {
            'type': 'aggregated',
            'insights': all_insights
        }
    }

    return intelligence_summary

def process_graph_commands(operations: List[Dict], graph_manager: GraphManager) -> None:
    """
    å¤„ç†å›¾æ“ä½œæŒ‡ä»¤åˆ—è¡¨.
    
    ä¼˜åŒ–æ“ä½œæ‰§è¡Œé¡ºåºï¼Œå…ˆæ·»åŠ èŠ‚ç‚¹ï¼Œå†åˆ é™¤/åºŸå¼ƒèŠ‚ç‚¹ï¼Œæœ€åæ›´æ–°èŠ‚ç‚¹ï¼Œ
    é¿å…å¯¹å·²åˆ é™¤èŠ‚ç‚¹è¿›è¡Œæ“ä½œï¼Œç¡®ä¿å›¾è°±çŠ¶æ€çš„ä¸€è‡´æ€§ã€‚
    
    Args:
        operations: å›¾æ“ä½œæŒ‡ä»¤åˆ—è¡¨ï¼Œæ¯ä¸ªæ“ä½œåŒ…å«commandå’Œç›¸å…³å‚æ•°
        graph_manager: å›¾è°±ç®¡ç†å™¨å®ä¾‹
    
    Returns:
        None
    """
    # å®šä¹‰ç³»ç»Ÿæ ‡å‡†çŠ¶æ€
    VALID_STATUSES = {'pending', 'in_progress', 'completed', 'failed', 'blocked', 'deprecated', 'stalled_orphan', 'completed_error'}

    # é¢„å¤„ç†ï¼šå»é‡ ADD_NODEï¼ˆæŒ‰ node_idï¼‰
    seen_add_ids = set()
    add_ops = []
    for op in operations:
        if op.get("command") == "ADD_NODE":
            node_data = op.get("node_data", {})
            node_id = node_data.get('id')
            if not node_id or node_id == "None":
                console.print(f"âš ï¸  è·³è¿‡æ— æ•ˆçš„ ADD_NODE æ“ä½œï¼ˆç¼ºå°‘ node_idï¼‰: {node_data}", style="yellow")
                continue
            if node_id in seen_add_ids:
                console.print(f"âš ï¸  æ£€æµ‹åˆ°é‡å¤çš„ ADD_NODE æ“ä½œï¼Œå·²å»é‡: {node_id}", style="yellow")
                continue
            seen_add_ids.add(node_id)
            add_ops.append(op)

    delete_ops = [op for op in operations if op.get("command") == "DELETE_NODE"]
    deprecate_ops = [op for op in operations if op.get("command") == "DEPRECATE_NODE"]  # å¤„ç†åºŸå¼ƒæ“ä½œ
    update_ops = [op for op in operations if op.get("command") == "UPDATE_NODE"]

    deleted_node_ids = set()

    # 1. é¦–å…ˆæ‰§è¡Œæ‰€æœ‰ ADD_NODE æ“ä½œï¼ˆå·²å»é‡ï¼‰
    for op in add_ops:
        node_data = op.get("node_data", {})
        node_id = node_data.get('id')

        # é˜²å¾¡æ€§æ£€æŸ¥ï¼šè·³è¿‡æ²¡æœ‰æœ‰æ•ˆ ID çš„èŠ‚ç‚¹
        if not node_id or node_id == "None":
            console.print(f"âš ï¸  è·³è¿‡æ— æ•ˆçš„ ADD_NODE æ“ä½œï¼ˆç¼ºå°‘ node_idï¼‰: {node_data}", style="yellow")
            continue
        # å¦‚æœèŠ‚ç‚¹å·²å­˜åœ¨ï¼Œé¿å…é‡å¤æ·»åŠ ï¼Œæ”¹ä¸º UPDATE_NODE åˆå¹¶å±æ€§
        if graph_manager.graph.has_node(node_id):
            updates = {k: v for k, v in node_data.items() if k not in {"id", "dependencies"}}
            if updates:
                graph_manager.update_node(node_id, updates)
            else:
                console.print(f"âš ï¸ èŠ‚ç‚¹å·²å­˜åœ¨ä¸”æ— å¯æ›´æ–°å­—æ®µï¼Œè·³è¿‡ ADD_NODE: {node_id}", style="yellow")
            continue

        graph_manager.add_subtask_node(
            node_id,
            node_data.get('description'),
            node_data.get('dependencies', []),
            node_data.get('priority', 1),
            reason=node_data.get('reason', ''),
            completion_criteria=node_data.get('completion_criteria', ''),
            mission_briefing=node_data.get('mission_briefing')
        )

    # 2. ç„¶åæ‰§è¡Œæ‰€æœ‰ DELETE/DEPRECATE æ“ä½œï¼Œå°†å…¶çŠ¶æ€æ›´æ–°ä¸º deprecated
    for op in delete_ops + deprecate_ops:
        node_id = op.get("node_id")
        if node_id:
            reason = op.get("reason", "æœªæä¾›åŸå› ")
            graph_manager.update_node(node_id, {"status": "deprecated", "summary": f"ä»»åŠ¡å·²è¢«è§„åˆ’å™¨åºŸå¼ƒã€‚åŸå› : {reason}"})
            deleted_node_ids.add(node_id)

    # 3. æœ€åæ‰§è¡Œæ‰€æœ‰ UPDATE_NODE æ“ä½œï¼Œä½†è·³è¿‡å·²åˆ é™¤çš„èŠ‚ç‚¹
    for op in update_ops:
        node_id = op.get("node_id")
        if node_id and node_id not in deleted_node_ids:
            updates = op.get("updates", {})

            # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å­˜åœ¨ï¼Œé¿å…KeyError
            if not graph_manager.graph.has_node(node_id):
                console.print(f"âš ï¸ å°è¯•æ›´æ–°ä¸å­˜åœ¨çš„èŠ‚ç‚¹ {node_id}ï¼Œè·³è¿‡æ“ä½œã€‚", style="yellow")
                continue

            # çŠ¶æ€éªŒè¯ï¼šæ£€æŸ¥å¹¶ä¿®æ­£éæ³•çŠ¶æ€å€¼
            if 'status' in updates:
                status = updates['status']
                current_node_status = graph_manager.graph.nodes[node_id].get('status')

                # [CRITICAL] ä¸¥ç¦å°† completed çŠ¶æ€æ”¹ä¸º deprecated
                # è¿™ä¼šç ´åå› æœé“¾å’ŒReflectorçš„åˆ¤æ–­æƒå¨æ€§
                if current_node_status == 'completed' and status == 'deprecated':
                    console.print(
                        f"âš ï¸  [çŠ¶æ€ä¿æŠ¤] Planner è¯•å›¾å°†å·²å®Œæˆä»»åŠ¡ {node_id} æ ‡è®°ä¸º 'deprecated'ã€‚",
                        style="bold yellow"
                    )
                    console.print(
                        f"   ğŸ“‹ åŸå› : Reflectorå·²åˆ¤å®šæ­¤ä»»åŠ¡ç›®æ ‡è¾¾æˆï¼ŒçŠ¶æ€ä¸å¯é€†è½¬ã€‚",
                        style="yellow"
                    )
                    console.print(
                        f"   ğŸ’¡ å»ºè®®: è‹¥éœ€è¡¥å……ï¼Œè¯·åˆ›å»ºæ–°ä»»åŠ¡å¹¶ä¾èµ–äº {node_id}ã€‚",
                        style="cyan"
                    )
                    # ç§»é™¤çŠ¶æ€æ›´æ–°ï¼Œä¿æŒ completed çŠ¶æ€
                    del updates['status']
                    # è®°å½•åˆ°èŠ‚ç‚¹çš„è­¦å‘Šä¿¡æ¯ä¸­
                    node_warnings = graph_manager.graph.nodes[node_id].get('warnings', [])
                    node_warnings.append(
                        f"[æ—¶é—´æˆ³ {time.time()}] Plannerå°è¯•å°†completedçŠ¶æ€æ”¹ä¸ºdeprecatedï¼Œå·²è¢«æ‹’ç»"
                    )
                    graph_manager.graph.nodes[node_id]['warnings'] = node_warnings
                # å¦‚æœå½“å‰çŠ¶æ€æ˜¯ç»ˆç»“çŠ¶æ€ï¼Œä¸”Plannerè¯•å›¾å°†å…¶é‡ç½®ä¸ºéç»ˆç»“çŠ¶æ€ï¼Œåˆ™å¿½ç•¥å¹¶è­¦å‘Š
                elif current_node_status in {'failed', 'deprecated', 'stalled_orphan', 'completed_error'} and status not in {'completed', 'failed', 'deprecated', 'stalled_orphan', 'completed_error'}:
                    console.print(
                        f"âš ï¸  Planner è¯•å›¾å°†å·²å¤„äºç»ˆç»“çŠ¶æ€ '{current_node_status}' çš„èŠ‚ç‚¹ {node_id} é‡ç½®ä¸º '{status}'ã€‚æ­¤æ“ä½œå·²è¢«å¿½ç•¥ã€‚",
                        style="yellow"
                    )
                    # ç§»é™¤çŠ¶æ€æ›´æ–°ï¼Œä¿æŒåŸç»ˆç»“çŠ¶æ€
                    del updates['status']
                elif status not in VALID_STATUSES:
                    # è®°å½•é”™è¯¯æ—¥å¿—åˆ°èŠ‚ç‚¹æœ¬èº«
                    original_status = status
                    updates['status'] = 'pending'
                    # å¦‚æœèŠ‚ç‚¹å­˜åœ¨ï¼Œå°è¯•æ·»åŠ è­¦å‘Šä¿¡æ¯
                    if graph_manager.graph.has_node(node_id):
                        node_warnings = graph_manager.graph.nodes[node_id].get('warnings', [])
                        node_warnings.append(f"æ£€æµ‹åˆ°éæ³•çŠ¶æ€ '{original_status}'ï¼Œå·²åœ¨æ—¶é—´æˆ³ {time.time()} ä¿®æ­£ä¸º 'pending'")
                        graph_manager.graph.nodes[node_id]['warnings'] = node_warnings
                    console.print(
                        f"âš ï¸  æ£€æµ‹åˆ°éæ³•çŠ¶æ€å€¼ '{original_status}' (èŠ‚ç‚¹ {node_id})ï¼Œè‡ªåŠ¨ä¿®æ­£ä¸º 'pending'",
                        style="yellow"
                    )
                    console.print(
                        f"   åˆæ³•çŠ¶æ€å€¼: {', '.join(sorted(VALID_STATUSES))}",
                        style="dim"
                    )

            graph_manager.update_node(node_id, updates)
        elif node_id in deleted_node_ids:
            console.print(f"âš ï¸ å°è¯•æ›´æ–°å·²åˆ é™¤çš„èŠ‚ç‚¹ {node_id}ï¼Œæ“ä½œå·²è·³è¿‡ã€‚", style="yellow")

    # å¤„ç† ADD_NODE æ“ä½œçš„çŠ¶æ€æ£€æŸ¥
    for op in add_ops:
        node_data = op.get("node_data", {})
        node_id = node_data.get('id')
        if node_data.get('status') and node_data['status'] not in VALID_STATUSES:
            original_status = node_data['status']
            node_data['status'] = 'pending'  # ä¿®æ­£æ–°èŠ‚ç‚¹çš„éæ³•çŠ¶æ€
            console.print(
                f"âš ï¸  ADD_NODE æ“ä½œä¸­æ£€æµ‹åˆ°éæ³•åˆå§‹çŠ¶æ€å€¼ '{original_status}' (èŠ‚ç‚¹ {node_id})ï¼Œè‡ªåŠ¨ä¿®æ­£ä¸º 'pending'",
                style="yellow"
            )
            if graph_manager.graph.has_node(node_id):
                node_warnings = graph_manager.graph.nodes[node_id].get('warnings', [])
                node_warnings.append(f"æ£€æµ‹åˆ°éæ³•åˆå§‹çŠ¶æ€ '{original_status}'ï¼Œå·²åœ¨æ—¶é—´æˆ³ {time.time()} ä¿®æ­£ä¸º 'pending'")
                graph_manager.graph.nodes[node_id]['warnings'] = node_warnings

    # å¤„ç†æœªçŸ¥æŒ‡ä»¤
    for op in operations:
        command = op.get("command")
        if command not in ["ADD_NODE", "DELETE_NODE", "UPDATE_NODE", "DEPRECATE_NODE"]:
            console.print(f"âŒ æœªçŸ¥çš„å›¾æŒ‡ä»¤: {command}", style="red")

def validate_causal_graph_updates(
    updates: Dict[str, List[Dict]],
    graph_manager: GraphManager,
    subtask_id: Optional[str] = None
) -> Dict[str, List[Dict]]:
    """
    æ ¡éªŒå› æœå›¾è°±æ›´æ–°çš„å®Œæ•´æ€§.
    
    åœ¨åº”ç”¨æ›´æ–°å‰æ£€æŸ¥å› æœé“¾å›¾è°±æ›´æ–°çš„åˆæ³•æ€§ï¼Œç¡®ä¿æ‰€æœ‰è¾¹å¼•ç”¨çš„èŠ‚ç‚¹éƒ½å­˜åœ¨ã€‚
    å¦‚æœè¾¹å¼•ç”¨çš„æ˜¯å½“å‰å­ä»»åŠ¡çš„æš‚å­˜èŠ‚ç‚¹ï¼Œè‡ªåŠ¨å°†è¯¥èŠ‚ç‚¹æå‡åˆ°æœ¬æ¬¡æ›´æ–°ä¸­ã€‚
    
    Args:
        updates: åŒ…å«nodeså’Œedgesçš„å› æœå›¾æ›´æ–°å­—å…¸
        graph_manager: å›¾è°±ç®¡ç†å™¨å®ä¾‹
        subtask_id: å½“å‰å­ä»»åŠ¡IDï¼ˆå¯é€‰ï¼‰
    
    Returns:
        Dict[str, List[Dict]]: éªŒè¯åçš„æ›´æ–°å­—å…¸ï¼ŒåŒ…å«æœ‰æ•ˆçš„nodeså’Œedges
    """
    if not updates or not isinstance(updates, dict):
        return {"nodes": [], "edges": []}

    nodes_to_add = list(updates.get("nodes", []) or [])
    edges_to_add = list(updates.get("edges", []) or [])

    # 1. æ”¶é›†æ‰€æœ‰æœ‰æ•ˆèŠ‚ç‚¹IDï¼šå·²æœ‰å› æœå›¾èŠ‚ç‚¹ + æœ¬æ¬¡æ–°å¢èŠ‚ç‚¹
    existing_node_ids = set(graph_manager.causal_graph.nodes)
    nodes_to_add_ids = {n.get("id") for n in nodes_to_add if n.get("id")}

    # 2. æ”¶é›†æš‚å­˜èŠ‚ç‚¹ï¼ˆä»…å½“å‰å­ä»»åŠ¡ï¼Œè‹¥æä¾›ï¼‰ä»¥æ”¯æŒè‡ªåŠ¨æå‡
    staged_nodes_by_id: Dict[str, Dict] = {}
    if subtask_id and graph_manager.graph.has_node(subtask_id):
        try:
            staged_list = graph_manager.graph.nodes[subtask_id].get("staged_causal_nodes", []) or []
            for sn in staged_list:
                sid = sn.get("id")
                if isinstance(sid, str) and sid:
                    staged_nodes_by_id[sid] = sn
        except Exception:
            # ä¿å®ˆå¤„ç†ï¼Œä¸å½±å“åç»­éªŒè¯
            staged_nodes_by_id = {}

    # 3. å¯¹è¾¹è¿›è¡Œé¢„æ£€æŸ¥ï¼›è‹¥ç¼ºå¤±ç«¯ç‚¹æ°å¥½å­˜åœ¨äºæš‚å­˜èŠ‚ç‚¹ï¼Œåˆ™å°†å…¶è‡ªåŠ¨åŠ å…¥ nodes_to_add
    auto_promoted_count = 0
    for edge in edges_to_add:
        for endpoint_key in ("source_id", "target_id"):
            endpoint_id = edge.get(endpoint_key)
            if not endpoint_id or not isinstance(endpoint_id, str):
                continue
            # å·²å­˜åœ¨æˆ–å·²åœ¨å¾…æ–°å¢é›†åˆä¸­åˆ™è·³è¿‡
            if endpoint_id in existing_node_ids or endpoint_id in nodes_to_add_ids:
                continue
            # å°è¯•ä»æš‚å­˜èŠ‚ç‚¹ä¸­æå‡
            staged_node = staged_nodes_by_id.get(endpoint_id)
            if staged_node:
                nodes_to_add.append(staged_node)
                nodes_to_add_ids.add(endpoint_id)
                auto_promoted_count += 1

    if auto_promoted_count:
        console.print(f"ğŸ”§  è‡ªåŠ¨æå‡ {auto_promoted_count} ä¸ªæš‚å­˜èŠ‚ç‚¹ä»¥æ»¡è¶³è¾¹å¼•ç”¨ï¼ˆå…ˆå»ºèŠ‚ç‚¹åå»ºè¾¹ï¼‰", style="cyan")

    # 4. é‡æ–°è®¡ç®—æœ‰æ•ˆIDé›†åˆå¹¶è¿‡æ»¤è¾¹
    valid_temp_node_ids = existing_node_ids.union(nodes_to_add_ids)
    validated_edges: List[Dict] = []
    for edge in edges_to_add:
        source_id = edge.get("source_id")
        target_id = edge.get("target_id")
        source_is_valid = source_id in valid_temp_node_ids
        target_is_valid = target_id in valid_temp_node_ids
        if source_is_valid and target_is_valid:
            validated_edges.append(edge)
        else:
            console.print(f"âš ï¸  [æ ¡éªŒ] ä¸¢å¼ƒæ— æ•ˆçš„å› æœé“¾è¾¹ï¼ŒèŠ‚ç‚¹ä¸å­˜åœ¨: {source_id} -> {target_id}", style="yellow")

    return {"nodes": nodes_to_add, "edges": validated_edges}

def process_causal_graph_commands(
    updates: Dict[str, List[Dict]],
    graph_manager: GraphManager
) -> Dict[str, str]:
    """
    å¤„ç†å› æœå›¾è°±çš„ç»“æ„åŒ–æ›´æ–°.
    
    å…ˆå¤„ç†æ‰€æœ‰èŠ‚ç‚¹æ·»åŠ ï¼Œå†å¤„ç†è¾¹çš„æ·»åŠ ï¼Œå¹¶ç»´æŠ¤ä¸´æ—¶IDåˆ°æ°¸ä¹…IDçš„æ˜ å°„ã€‚
    
    Args:
        updates: åŒ…å«nodeså’Œedgesçš„æ›´æ–°å­—å…¸
        graph_manager: å›¾è°±ç®¡ç†å™¨å®ä¾‹
    
    Returns:
        Dict[str, str]: ä¸´æ—¶IDåˆ°æ°¸ä¹…IDçš„æ˜ å°„å­—å…¸
    """
    node_id_map = {}  # Maps the Reflector's temporary ID to the GraphManager's permanent ID

    nodes_to_add = updates.get("nodes", [])
    edges_to_add = updates.get("edges", [])

    # 1. é¦–å…ˆå¤„ç†æ‰€æœ‰èŠ‚ç‚¹æ·»åŠ 
    for node_data in nodes_to_add:
        temp_id = node_data.get("id")
        if temp_id:
            # The add_causal_node method creates a deterministic ID
            permanent_id = graph_manager.add_causal_node(node_data)
            node_id_map[temp_id] = permanent_id

    # 2. ç„¶åå¤„ç†æ‰€æœ‰è¾¹çš„æ·»åŠ 
    for edge_data in edges_to_add:
        source_temp_id = edge_data.get("source_id")
        target_temp_id = edge_data.get("target_id")

        # Translate temporary IDs to permanent IDs
        source_perm_id = node_id_map.get(source_temp_id)
        target_perm_id = node_id_map.get(target_temp_id)

        # If an ID is not in the map, it might be an existing node's permanent ID
        if not source_perm_id:
            source_perm_id = source_temp_id
        if not target_perm_id:
            target_perm_id = target_temp_id

        if source_perm_id and target_perm_id:
            label = edge_data.pop("label", "SUPPORTS")
            graph_manager.add_causal_edge(source_perm_id, target_perm_id, label, **edge_data)
            # Trigger confidence propagation
            graph_manager.update_hypothesis_confidence(target_perm_id, edge_data.get("label"))
        else:
            console.print(f"âš ï¸  æ— æ³•åˆ›å»ºå› æœé“¾å…³ç³»è¾¹ï¼Œæºæˆ–ç›®æ ‡IDæœªæ‰¾åˆ°: {source_temp_id} -> {target_temp_id}", style="yellow")

    return node_id_map

def save_logs(
    log_dir: str,
    metrics: Dict,
    run_log: List,
    final_save: bool = False
) -> None:
    """
    ä¿å­˜æŒ‡æ ‡å’Œè¿è¡Œæ—¥å¿—çš„å¿«ç…§.

    
    Args:
        log_dir: æ—¥å¿—ç›®å½•è·¯å¾„
        metrics: æŒ‡æ ‡å­—å…¸
        run_log: è¿è¡Œæ—¥å¿—åˆ—è¡¨
        final_save: æ˜¯å¦ä¸ºæœ€ç»ˆä¿å­˜ï¼Œé»˜è®¤False
    
    Returns:
        None
    """
    # Always update total time
    metrics["total_time_seconds"] = time.time() - metrics["start_time"]

    if final_save:
        metrics["end_time"] = time.time()

    # Create a deep copy for serialization to avoid issues with defaultdict
    # Sanitize any problematic characters in metrics before JSON serialization
    metrics_copy = json.loads(json.dumps(metrics, ensure_ascii=False))
    if "tool_calls" in metrics_copy:
        metrics_copy["tool_calls"] = dict(metrics["tool_calls"])

    try:
        metrics_path = os.path.join(log_dir, "metrics.json")
        with open(metrics_path, 'w', encoding='utf-8', errors='replace') as f:
            json.dump(metrics_copy, f, ensure_ascii=False, indent=4)

        with open(os.path.join(log_dir, "run_log.json"), 'w', encoding='utf-8', errors='replace') as f:
            json.dump(run_log, f, ensure_ascii=False, indent=4)
    except Exception as e:
        console.print(f"[bold red]Error saving logs: {e}[/bold red]")

    if final_save:
        console.print(Panel(f"Final logs and metrics saved to {log_dir}", title="[bold green]Run Finished[/bold green]"))

def update_global_metrics(metrics: Dict, update_dict: Dict):
    """Aggregates metrics from a component into the global metrics dictionary."""
    if not update_dict:
        return

    metrics["prompt_tokens"] += update_dict.get("prompt_tokens", 0)
    metrics["completion_tokens"] += update_dict.get("completion_tokens", 0)
    metrics["total_tokens"] += update_dict.get("prompt_tokens", 0) + update_dict.get("completion_tokens", 0)
    metrics["cost_cny"] += update_dict.get("cost_cny", 0)
    
    # ä¿®å¤: execution_stepsä¸ç”¨ç´¯åŠ ï¼Œç›´æ¥ä½¿ç”¨executorè¿”å›çš„å€¼
    # executorå·²ç»åœ¨å†…éƒ¨å®æ—¶ç»´æŠ¤äº†æ€»æ‰§è¡Œæ­¥æ•°
    if "execution_steps" in update_dict:
        # ç›´æ¥è¦†ç›–ï¼Œä¸ç´«åŠ ï¼ˆexecutorè¿”å›çš„æ˜¯ç´¯è®¡å€¼ï¼‰
        metrics["execution_steps"] = update_dict["execution_steps"]
    
    # plan_stepså’Œreflect_stepséœ€è¦ç´¯åŠ ï¼ˆå› ä¸ºæ¯æ¬¡è°ƒç”¨éƒ½æ˜¯+1ï¼‰
    metrics["plan_steps"] += update_dict.get("plan_steps", 0)
    metrics["execute_steps"] += update_dict.get("execute_steps", 0)
    metrics["reflect_steps"] += update_dict.get("reflect_steps", 0)

    # ä¿®å¤: tool_callsä¸ç”¨ç´¯åŠ ï¼Œexecutorå·²ç»åœ¨metrics.jsonä¸­å®æ—¶ç»´æŠ¤
    # æˆ‘ä»¬åªéœ€è¦ä»æ–‡ä»¶è¯»å–æœ€æ–°å€¼ï¼Œè€Œä¸æ˜¯å†æ¬¡ç´¯åŠ 
    if "tool_calls" in update_dict:
        # åˆå¹¶tool_callsï¼ˆä½¿ç”¨æ›´å¤§çš„å€¼ï¼Œé¿å…è¦†ç›–ï¼‰
        for tool, count in update_dict["tool_calls"].items():
            current_count = metrics["tool_calls"].get(tool, 0)
            # åªåœ¨update_dictçš„å€¼æ›´å¤§æ—¶æ›´æ–°ï¼ˆexecutorè¿”å›çš„æ˜¯ç´¯è®¡å€¼ï¼‰
            if count > current_count:
                metrics["tool_calls"][tool] = count

def update_reflector_context_after_reflection(reflector_context, reflection_output, subtask_id, status, graph_manager):
    """åœ¨åæ€å®Œæˆåæ›´æ–°ReflectorContextçŠ¶æ€"""
    from core.data_contracts import ReflectionInsight

    audit_result = reflection_output.get('audit_result', {})
    key_findings = reflection_output.get('key_findings', [])

    # ç¡®ä¿key_findingsæ˜¯å­—ç¬¦ä¸²åˆ—è¡¨
    def _ensure_string_findings(findings):
        if not findings:
            return []

        string_findings = []
        for finding in findings:
            if isinstance(finding, str):
                string_findings.append(finding)
            elif isinstance(finding, dict):
                # å°è¯•ä»å­—å…¸ä¸­æå–æ–‡æœ¬å†…å®¹
                if 'description' in finding:
                    string_findings.append(finding['description'])
                elif 'text' in finding:
                    string_findings.append(finding['text'])
                elif 'finding' in finding:
                    string_findings.append(finding['finding'])
                else:
                    # ä½œä¸ºæœ€åæ‰‹æ®µï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                    string_findings.append(str(finding))
            else:
                string_findings.append(str(finding))
        return string_findings

    safe_key_findings = _ensure_string_findings(key_findings)

    # åˆ›å»ºåæ€æ´å¯Ÿ
    insight = ReflectionInsight(
        timestamp=time.time(),
        subtask_id=subtask_id,
        normalized_status=status,
        key_insight="; ".join(safe_key_findings) if safe_key_findings else "No key insights",
        failure_pattern=_extract_failure_pattern(audit_result, safe_key_findings),
        full_reflection_report=reflection_output,
        llm_reflection_prompt=reflection_output.get('llm_reflection_prompt'),
        llm_reflection_response=json.dumps(reflection_output, ensure_ascii=False, indent=2)
    )

    # æ·»åŠ åˆ°åæ€æ—¥å¿—
    reflector_context.add_insight(insight)

    return reflector_context

def _extract_failure_pattern(audit_result, key_findings):
    """ä»å®¡è®¡ç»“æœå’Œå…³é”®å‘ç°ä¸­æå–å¤±è´¥æ¨¡å¼"""
    status = audit_result.get('status', '')

    if status in ['FAILED', 'PARTIAL_SUCCESS']:
        # å°è¯•ä»å…³é”®å‘ç°ä¸­æå–æ¨¡å¼
        for finding in key_findings:
            if any(pattern in finding for pattern in ['HTTP_', 'timeout', 'connection refused', 'permission denied']):
                return finding

    return None

async def compress_planner_context_if_needed(planner_context, llm_client):
    """æ£€æŸ¥å¹¶æ‰§è¡ŒPlannerContextçš„å‹ç¼©ï¼ˆå¦‚æœéœ€è¦ï¼‰ã€‚"""
    if hasattr(planner_context, '_needs_compression') and planner_context._needs_compression:
        try:
            # è·å–éœ€è¦å‹ç¼©çš„å†å²è®°å½•
            if len(planner_context.planning_history) > PLANNER_HISTORY_WINDOW:
                history_to_compress = planner_context.planning_history[:-PLANNER_HISTORY_WINDOW]

                # å°†PlanningAttemptè½¬æ¢ä¸ºå¯¹è¯æ ¼å¼ç”¨äºå‹ç¼©
                messages_to_compress = []
                for attempt in history_to_compress:
                    if attempt.llm_input_prompt:
                        messages_to_compress.append({
                            'role': 'user',
                            'content': attempt.llm_input_prompt
                        })
                    if attempt.llm_output_response:
                        messages_to_compress.append({
                            'role': 'assistant',
                            'content': attempt.llm_output_response
                        })

                if messages_to_compress:
                    # ä½¿ç”¨LLMClientçš„ç°æœ‰å‹ç¼©åŠŸèƒ½
                    summary = await llm_client.summarize_conversation(messages_to_compress)
                    if summary:
                        # æ›´æ–°å‹ç¼©æ‘˜è¦
                        if planner_context.compressed_history_summary:
                            planner_context.compressed_history_summary += "\n\n" + summary
                        else:
                            planner_context.compressed_history_summary = summary

                        # ç§»é™¤å·²å‹ç¼©çš„å†å²è®°å½•ï¼Œä¿ç•™çª—å£å†…çš„è®°å½•
                        planner_context.planning_history = planner_context.planning_history[-PLANNER_HISTORY_WINDOW:]
                        planner_context.compression_count += 1
                        planner_context._needs_compression = False

                        console.print(f"[green]âœ“ Plannerä¸Šä¸‹æ–‡å·²å‹ç¼©ï¼Œå½“å‰å‹ç¼©æ¬¡æ•°: {planner_context.compression_count}[/green]")

        except Exception as e:
            console.print(f"[yellow]âš ï¸ Plannerä¸Šä¸‹æ–‡å‹ç¼©å¤±è´¥: {e}[/yellow]")
            planner_context._needs_compression = False

async def compress_reflector_context_if_needed(reflector_context, llm_client):
    """æ£€æŸ¥å¹¶æ‰§è¡ŒReflectorContextçš„å‹ç¼©ï¼ˆå¦‚æœéœ€è¦ï¼‰ã€‚"""
    if hasattr(reflector_context, '_needs_compression') and reflector_context._needs_compression:
        try:
            # è·å–éœ€è¦å‹ç¼©çš„åæ€è®°å½•
            if len(reflector_context.reflection_log) > REFLECTOR_HISTORY_WINDOW:
                insights_to_compress = reflector_context.reflection_log[:-REFLECTOR_HISTORY_WINDOW]

                # å°†ReflectionInsightè½¬æ¢ä¸ºå¯¹è¯æ ¼å¼ç”¨äºå‹ç¼©
                messages_to_compress = []
                for insight in insights_to_compress:
                    if insight.llm_reflection_prompt:
                        messages_to_compress.append({
                            'role': 'user',
                            'content': insight.llm_reflection_prompt
                        })
                    if insight.llm_reflection_response:
                        messages_to_compress.append({
                            'role': 'assistant',
                            'content': insight.llm_reflection_response
                        })

                if messages_to_compress:
                    # ä½¿ç”¨LLMClientçš„ç°æœ‰å‹ç¼©åŠŸèƒ½
                    summary = await llm_client.summarize_conversation(messages_to_compress)
                    if summary:
                        # æ›´æ–°å‹ç¼©æ‘˜è¦
                        if reflector_context.compressed_reflection_summary:
                            reflector_context.compressed_reflection_summary += "\n\n" + summary
                        else:
                            reflector_context.compressed_reflection_summary = summary

                        # ç§»é™¤å·²å‹ç¼©çš„åæ€è®°å½•ï¼Œä¿ç•™çª—å£å†…çš„è®°å½•
                        reflector_context.reflection_log = reflector_context.reflection_log[-REFLECTOR_HISTORY_WINDOW:]
                        reflector_context.compression_count += 1
                        reflector_context._needs_compression = False

                        console.print(f"[green]âœ“ Reflectorä¸Šä¸‹æ–‡å·²å‹ç¼©ï¼Œå½“å‰å‹ç¼©æ¬¡æ•°: {reflector_context.compression_count}[/green]")

        except Exception as e:
            console.print(f"[yellow]âš ï¸ Reflectorä¸Šä¸‹æ–‡å‹ç¼©å¤±è´¥: {e}[/yellow]")
            reflector_context._needs_compression = False

def verify_and_handle_orphans(operations: List[Dict], graph_manager: GraphManager, console: Console) -> List[Dict]:
    """
    åœ¨æ‰§è¡Œå›¾æ“ä½œå‰ï¼ŒéªŒè¯Planneræ˜¯å¦æ­£ç¡®å¤„ç†äº†å­¤å„¿èŠ‚ç‚¹ã€‚
    å¦‚æœæ²¡æœ‰ï¼Œåˆ™è‡ªåŠ¨ç”Ÿæˆä¿®å¤æŒ‡ä»¤ï¼Œä½œä¸ºä»£ç çº§å®‰å…¨ç½‘ã€‚
    """
    # æ‰¾å‡ºæ‰€æœ‰å°†è¢«åºŸå¼ƒçš„èŠ‚ç‚¹ID
    deprecated_node_ids = set()
    for op in operations:
        if op.get("command") == "UPDATE_NODE" and op.get("updates", {}).get("status") == "deprecated":
            deprecated_node_ids.add(op.get("node_id"))
        elif op.get("command") == "DELETE_NODE": # å…¼å®¹æ—§çš„æˆ–ç›´æ¥çš„åˆ é™¤æŒ‡ä»¤
            deprecated_node_ids.add(op.get("node_id"))

    if not deprecated_node_ids:
        return operations

    # æ‰¾å‡ºæ‰€æœ‰å³å°†æˆä¸ºå­¤å„¿çš„èŠ‚ç‚¹
    potential_orphans = {}
    # ä½¿ç”¨ list(graph_manager.graph.nodes(data=True)) é¿å…åœ¨éå†æ—¶ä¿®æ”¹å›¾
    for node_id, data in list(graph_manager.graph.nodes(data=True)):
        if data.get('type') != 'subtask':
            continue

        dependencies = [u for u, v in graph_manager.graph.in_edges(node_id) if graph_manager.graph.edges[u, v].get('type') == 'dependency']
        # å¦‚æœä¸€ä¸ªèŠ‚ç‚¹çš„æŸä¸ªä¾èµ–åœ¨å¾…åºŸå¼ƒåˆ—è¡¨é‡Œ
        orphaned_by_parents = [dep for dep in dependencies if dep in deprecated_node_ids]

        if orphaned_by_parents:
            potential_orphans[node_id] = orphaned_by_parents

    if not potential_orphans:
        return operations

    # æ£€æŸ¥Planneræ˜¯å¦å·²ç»å¤„ç†äº†è¿™äº›å­¤å„¿
    handled_orphans = set()
    for op in operations:
        if op.get('command') in ['UPDATE_NODE', 'DELETE_NODE']:
            if op.get('node_id') in potential_orphans:
                handled_orphans.add(op.get('node_id'))

    # å¯¹æœªè¢«å¤„ç†çš„å­¤å„¿ï¼Œç”Ÿæˆä¿®å¤æŒ‡ä»¤
    fix_operations = []
    for orphan_id, deleted_parents in potential_orphans.items():
        if orphan_id not in handled_orphans:
            # æ–°çš„ä¿®å¤ç­–ç•¥ï¼šå°†å­¤å„¿èŠ‚ç‚¹æ ‡è®°ä¸ºåœæ»çŠ¶æ€ï¼Œè€Œä¸æ˜¯é‡æ–°è¿æ¥
            fix_op = {
                "command": "UPDATE_NODE",
                "node_id": orphan_id,
                "updates": {
                    "status": "stalled_orphan",
                    "summary": f"Dependency on {deleted_parents} was removed by the Planner without providing a new dependency."
                }
            }
            fix_operations.append(fix_op)
            console.print(Panel(f"æ£€æµ‹åˆ°Planneræœªå¤„ç†çš„å­¤å„¿èŠ‚ç‚¹ [bold yellow]{orphan_id}[/bold yellow]ã€‚è‡ªåŠ¨ç”Ÿæˆä¿®å¤æŒ‡ä»¤ï¼Œå°†å…¶çŠ¶æ€æ›´æ–°ä¸º 'stalled_orphan'ã€‚", title="âš ï¸ [bold red]ä»£ç çº§ä¿®å¤[/bold red]", style="purple"))

    return operations + fix_operations

def get_next_executable_subtask_batch(graph: GraphManager) -> List[str]:
    """è·å–ä¸‹ä¸€ä¸ªå¯å¹¶è¡Œæ‰§è¡Œçš„ä»»åŠ¡æ‰¹æ¬¡ã€‚"""
    pending_subtasks = [
        node for node, data in graph.graph.nodes(data=True)
        if data.get('type') == 'subtask' and data.get('status') in ['pending', 'ready', 'active', 'in_progress']
    ]

    non_terminal_subtasks = [
        node for node in pending_subtasks
        if graph.graph.nodes[node].get('status') not in ['completed', 'failed', 'deprecated', 'stalled_orphan', 'completed_error']
    ]

    executable_tasks = []
    for node in non_terminal_subtasks:
        dependencies = [u for u, v in graph.graph.in_edges(node) if graph.graph.edges[u, v].get('type') == 'dependency']
        if all(str(graph.graph.nodes[dep].get('status', '')).startswith(('completed', 'deprecated', 'failed')) for dep in dependencies):
            executable_tasks.append(node)

    if not executable_tasks:
        return []

    # è¿”å›æ‰€æœ‰å¯æ‰§è¡Œçš„ä»»åŠ¡ï¼Œä»¥æé«˜å¹¶å‘æ•ˆç‡
    return executable_tasks


async def handle_cli_approval(op_id: str, plan_data: List[Dict[str, Any]]):
    """
    å¤„ç† CLI ç«¯çš„äººå·¥å®¡æ‰¹ã€‚
    ä¸ Web ç«¯å®¡æ‰¹å¹¶è¡Œè¿è¡Œï¼Œä»»ä½•ä¸€æ–¹å…ˆæäº¤å†³ç­–å³ç”Ÿæ•ˆã€‚
    """
    if not sys.stdin.isatty():
        console.print("[dim]éäº¤äº’å¼ç¯å¢ƒï¼Œè·³è¿‡ CLI å®¡æ‰¹ç›‘å¬ã€‚[/dim]")
        return

    loop = asyncio.get_running_loop()
    
    # 1. å±•ç¤ºè®¡åˆ’æ¦‚è¦
    console.print(Panel(f"å¾…å®¡æ‰¹è®¡åˆ’ ({len(plan_data)} ops):", title="[bold yellow]HITL CLI[/bold yellow]", style="yellow"))
    for i, op in enumerate(plan_data):
        cmd = op.get('command')
        node_id = op.get('node_id') or op.get('node_data', {}).get('id')
        desc = op.get('node_data', {}).get('description') or op.get('updates') or op.get('reason')
        console.print(f"  {i+1}. [bold]{cmd}[/bold] {node_id}: {str(desc)[:100]}...")

    console.print("\nè¯·é€‰æ‹©æ“ä½œ: [bold green]y[/bold green] (æ‰¹å‡†), [bold red]n[/bold red] (æ‹’ç»), [bold blue]m[/bold blue] (ä¿®æ”¹)")
    console.print("HITL > ", end="")
    
    # 2. é˜»å¡ç­‰å¾…è¾“å…¥ (è¿è¡Œåœ¨ executor ä¸­ä»¥å…é˜»å¡ä¸»å¾ªç¯)
    try:
        while True:
            try:
                # ç¨å¾®è®©å‡ºæ§åˆ¶æƒï¼Œç¡®ä¿ Web Server ä»»åŠ¡æœ‰æœºä¼šè¿è¡Œ
                await asyncio.sleep(0.1)
                
                # ä½¿ç”¨ sys.stdin.readline æ›¿ä»£ inputï¼Œé¿å…æŸäº›ç¯å¢ƒä¸‹çš„ GIL æˆ–é”ç«äº‰é—®é¢˜
                # æ³¨æ„ï¼šreadline ä¼šä¿ç•™æ¢è¡Œç¬¦ï¼Œéœ€è¦ strip
                line = await loop.run_in_executor(None, sys.stdin.readline)
                if not line: # EOF
                    break
                    
                choice = line.strip().lower()
                
                if choice == 'y':
                    intervention_manager.submit_decision(op_id, "APPROVE")
                    console.print("âœ… CLI: å·²æ‰¹å‡†è®¡åˆ’ã€‚")
                    break
                elif choice == 'n':
                    intervention_manager.submit_decision(op_id, "REJECT")
                    console.print("âŒ CLI: å·²æ‹’ç»è®¡åˆ’ã€‚")
                    break
                elif choice == 'm':
                    # ä¿®æ”¹æ¨¡å¼ï¼šè°ƒç”¨ç³»ç»Ÿç¼–è¾‘å™¨
                    import tempfile
                    import os
                    import subprocess
                    
                    editor = os.getenv('EDITOR', 'vim')
                    with tempfile.NamedTemporaryFile(mode='w+', suffix='.json', delete=False) as tf:
                        json.dump(plan_data, tf, indent=2, ensure_ascii=False)
                        tf_path = tf.name
                    
                    try:
                        console.print(f"æ­£åœ¨æ‰“å¼€ç¼–è¾‘å™¨ ({editor})...")
                        subprocess.call([editor, tf_path])
                        
                        with open(tf_path, 'r') as tf:
                            modified_data = json.load(tf)
                        
                        intervention_manager.submit_decision(op_id, "MODIFY", modified_data)
                        console.print("âœï¸ CLI: å·²æäº¤ä¿®æ”¹åçš„è®¡åˆ’ã€‚")
                        os.unlink(tf_path)
                        break
                    except Exception as e:
                        console.print(f"[bold red]ä¿®æ”¹å¤±è´¥: {e}[/bold red]")
                        console.print("è¯·é‡è¯•æˆ–ä½¿ç”¨ y/nã€‚")
                        console.print("HITL > ", end="")
                else:
                    console.print("æ— æ•ˆè¾“å…¥ã€‚è¯·è¾“å…¥ y, n æˆ– mã€‚")
                    console.print("HITL > ", end="")
                
            except Exception as e:
                console.print(f"[dim]CLI è¾“å…¥é”™è¯¯: {e}[/dim]")
                await asyncio.sleep(1) # å‡ºé”™åé¿è®©
                
    except asyncio.CancelledError:
        # ä»»åŠ¡è¢«å–æ¶ˆï¼ˆè¯´æ˜ Web ç«¯å·²å¤„ç†ï¼‰
        console.print("\n[dim]Web ç«¯å·²æäº¤å†³ç­–ï¼ŒCLI å®¡æ‰¹å–æ¶ˆã€‚[/dim]")


async def main():
    parser = argparse.ArgumentParser(description="LuaN1ao Agent")
    parser.add_argument("--goal", required=True, help="The penetration testing goal for the agent.")
    parser.add_argument("--task-name", default="default_task", help="The name of the task, used for logging.")
    parser.add_argument("--log-dir", help="The directory to save logs. If not provided, defaults to logs/task_name/timestamp.")

    # LLM Configuration arguments
    parser.add_argument("--llm-api-base-url", help="The base URL for the LLM API.")
    parser.add_argument("--llm-api-key", help="The API key for the LLM service.")
    parser.add_argument("--llm-planner-model", help="Model to use for the Planner role.")
    parser.add_argument("--llm-executor-model", help="Model to use for the Executor role.")
    parser.add_argument("--llm-reflector-model", help="Model to use for the Reflector role.")
    parser.add_argument("--llm-default-model", help="Default model to use for other roles.")
    parser.add_argument("--llm-expert-model", help="Model to use for the Expert Analysis role.")
    parser.add_argument("--web", action="store_true", help="å¯åŠ¨å†…ç½® Web å¯è§†åŒ–æœåŠ¡")
    parser.add_argument("--web-port", type=int, default=DEFAULT_WEB_PORT, help="Web æœåŠ¡ç«¯å£")
    parser.add_argument(
        "--output-mode", 
        type=str, 
        choices=["simple", "default", "debug"], 
        default=OUTPUT_MODE, # Use OUTPUT_MODE from config as default
        help="æ§åˆ¶å°è¾“å‡ºæ¨¡å¼: simple, default, debug"
    )

    args = parser.parse_args()
    goal = args.goal
    task_name = args.task_name
    log_dir = args.log_dir  # è·å–ä¼ é€’çš„ log_dir

    # ç¡®å®šæœ€ç»ˆçš„è¾“å‡ºæ¨¡å¼
    effective_output_mode = args.output_mode

    console.print(Panel(f"LuaN1ao Agent å¯åŠ¨ã€‚Task: {task_name}", title="å¯åŠ¨ä¿¡æ¯", style="bold blue"))

    # Create custom models dict from command line args
    llm_models = {
        "default": args.llm_default_model or os.getenv("LLM_DEFAULT_MODEL", "qwen3-max"),
        "planner": args.llm_planner_model or os.getenv("LLM_PLANNER_MODEL", "qwen3-max"),
        "executor": args.llm_executor_model or os.getenv("LLM_EXECUTOR_MODEL", "qwen3-max"),
        "reflector": args.llm_reflector_model or os.getenv("LLM_REFLECTOR_MODEL", "qwen3-max"),
        "expert_analysis": args.llm_expert_model or os.getenv("LLM_EXPERT_MODEL", "qwen3-max"),
    }

    # Override configuration from command line if provided
    if args.llm_api_base_url or args.llm_api_key:
        # Temporarily update the configuration module to reflect the command-line arguments
        import conf.config
        if args.llm_api_base_url:
            conf.config.LLM_API_BASE_URL = args.llm_api_base_url
        if args.llm_api_key:
            conf.config.LLM_API_KEY = args.llm_api_key
        # Update models as well
        conf.config.LLM_MODELS = llm_models

    llm = LLMClient()

    # å¦‚æœæ²¡æœ‰æä¾› log_dirï¼Œä½¿ç”¨é»˜è®¤é€»è¾‘
    if not log_dir:
        log_dir = os.path.join("logs", task_name, datetime.now().strftime("%Y%m%d_%H%M%S"))

    os.makedirs(log_dir, exist_ok=True)  # ç¡®ä¿ç›®å½•å­˜åœ¨

    # è®¾ç½®LLMçš„op_idç”¨äºäº‹ä»¶å‘é€
    llm.op_id = os.path.basename(log_dir)

    # å¯è§†åŒ– Web æœåŠ¡ï¼ˆå¯é€‰ï¼‰
    if args.web:
        try:
            import uvicorn
            from web.server import app
            import socket

            def is_port_in_use(port: int) -> bool:
                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                    return s.connect_ex(('127.0.0.1', port)) == 0

            # è‡ªåŠ¨å¯»æ‰¾å¯ç”¨ç«¯å£
            web_port = args.web_port
            while is_port_in_use(web_port):
                web_port += 1
            
            async def start_web():
                config = uvicorn.Config(app, host=KNOWLEDGE_SERVICE_HOST, port=web_port, log_level="critical")
                server = uvicorn.Server(config)
                await server.serve()
            
            asyncio.create_task(start_web())
            
            web_url = f"http://{KNOWLEDGE_SERVICE_HOST}:{web_port}/?op_id={os.path.basename(log_dir)}"
            console.print(Panel(
                f"å¯è§†åŒ– Web æœåŠ¡å·²å¯åŠ¨: [link={web_url}]{web_url}[/link]\n"
                f"[dim]æ³¨æ„: æ­¤WebæœåŠ¡ä»…ç”¨äºå½“å‰ä»»åŠ¡çš„å¯è§†åŒ–ï¼Œéšä»»åŠ¡ç»“æŸè€Œåœæ­¢ã€‚[/dim]", 
                style="bold green",
                title="Web UI"
            ))
        except Exception as e:
            console.print(Panel(f"Web æœåŠ¡å¯åŠ¨å¤±è´¥: {e}", style="bold red"))

    # å®‰å…¨è­¦å‘Šæ¨ªå¹…
    console.print(Panel(
        "[bold red]âš ï¸ ä¸¥é‡å®‰å…¨è­¦å‘Šï¼šæ­¤AgentåŒ…å«æ‰§è¡Œä»»æ„ä»£ç çš„å·¥å…·ï¼[/bold red]\n\n"
        "å·¥å…· [bold yellow]python_exec[/bold yellow] å’Œ [bold yellow]shell_exec[/bold yellow] å…è®¸Agentæ‰§è¡Œç³»ç»Ÿå‘½ä»¤å’ŒPythonä»£ç ã€‚è¿™èµ‹äºˆäº†Agentå¼ºå¤§çš„èƒ½åŠ›ï¼Œä½†ä¹Ÿæ„å‘³ç€ï¼š\n"
        "- [bold yellow]å­˜åœ¨è¿œç¨‹ä»£ç æ‰§è¡Œ (RCE) é£é™©[/bold yellow]ï¼šå¦‚æœAgentè¢«æ¶æ„æŒ‡ä»¤æ§åˆ¶æˆ–åœ¨ä¸å®‰å…¨ç¯å¢ƒä¸­è¿è¡Œï¼Œå¯èƒ½å¯¹æ‚¨çš„ç³»ç»Ÿé€ æˆæŸå®³ã€‚\n"
        "- [bold yellow]ä¸æä¾›ä¸¥æ ¼æ²™ç®±éš”ç¦»[/bold yellow]ï¼šå½“å‰ Agent åœ¨åŒä¸€è¿›ç¨‹ä¸­æ‰§è¡Œï¼Œæ²¡æœ‰ä¸¥æ ¼çš„æ²™ç®±éš”ç¦»ã€‚\n\n"
        "[bold red]å¼ºçƒˆå»ºè®®æ‚¨åœ¨éš”ç¦»çš„ã€å—æ§çš„ç¯å¢ƒä¸­è¿è¡Œæœ¬Agent (ä¾‹å¦‚ï¼šDockerå®¹å™¨æˆ–è™šæ‹Ÿæœº)ï¼Œå¹¶ä¸”ä¸è¦åœ¨åŒ…å«æ•æ„Ÿæ•°æ®æˆ–å…³é”®æœåŠ¡çš„æœºå™¨ä¸Šè¿è¡Œã€‚[/bold red]\n\n"
        "è¯·è°¨æ…ä½¿ç”¨ï¼Œå¹¶ç¡®ä¿æ‚¨å®Œå…¨ç†è§£å…¶å®‰å…¨å«ä¹‰ã€‚",
        title="[bold red]!!! å®‰å…¨è­¦å‘Š !!![/bold red]",
        title_align="center",
        border_style="red"
    ))

    # Set up file-based console logging
    text_log_path = os.path.join(log_dir, "console_output.log")
    try:
        log_file = open(text_log_path, "w", encoding="utf-8")
        # Use the new function to create a console that writes to both stdout and the file
        new_console = init_console_with_file(log_file)
        set_console(new_console)
    except Exception as e:
        console.print(f"[bold red]Error setting up file logging: {e}[/bold red]")

    # Initialize metrics and run log
    metrics = {
        "task_name": task_name,
        "start_time": time.time(),
        "end_time": None,
        "total_time_seconds": 0,
        "prompt_tokens": 0,
        "completion_tokens": 0,
        "total_tokens": 0,
        "cost_cny": 0,
        "tool_calls": defaultdict(int),
        "success_info": {"found": False, "reason": ""},
        "execution_steps": 0,
        "plan_steps": 0,
        "execute_steps": 0,
        "reflect_steps": 0,
        "artifacts_found": 0,
        "causal_graph_nodes": [],
        "deployment_time": 0,  # åˆå§‹åŒ–éƒ¨ç½²æ—¶é—´
    }
    run_log = []

    # åˆå§‹åŒ–æœåŠ¡ï¼Œåœ¨ä¸»å¾ªç¯å¤–åˆå§‹åŒ–MCPä¼šè¯ï¼Œå®ç°çœŸæ­£çš„æŒä¹…åŒ–è¿æ¥
    await initialize_sessions()
    await tool_manager.refresh_tools_async()  # åˆå§‹åŒ–å·¥å…·ç¼“å­˜

    # ç¡®ä¿çŸ¥è¯†æœåŠ¡è¿è¡Œ
    await ensure_knowledge_service(console)

    task_id = None # åœ¨å¾ªç¯å¤–åˆå§‹åŒ–

    try:
        # 1. åˆå§‹åŒ–
        task_id = generate_task_id()
        metrics["task_id"] = task_id
        mcp_service.CURRENT_TASK_ID = task_id # è®¾ç½®å…¨å±€ä»»åŠ¡IDä¾›å·¥å…·ä½¿ç”¨
        console.print(Panel(f"Task: {task_name}\nTask ID: {task_id}\nGoal: {goal}", title="ä»»åŠ¡åˆå§‹åŒ–", style="bold green"))
        run_log.append({"event": "task_initialized", "task_id": task_id, "goal": goal, "timestamp": time.time()})

        graph_manager = GraphManager(task_id, goal)
        # Set op_id for event emission
        graph_manager.set_op_id(os.path.basename(log_dir))
        if register_graph:
            try:
                register_graph(os.path.basename(log_dir), graph_manager, log_dir=log_dir)
            except Exception:
                pass
        # è®°å½•éƒ¨ç½²æ—¶é—´ï¼ˆgraph_manageråˆå§‹åŒ–å®Œæˆå³è§†ä¸ºéƒ¨ç½²å®Œæˆï¼‰
        metrics["deployment_time"] = time.time() - metrics["start_time"]
        planner = Planner(llm, output_mode=effective_output_mode)
        reflector = Reflector(llm, output_mode=effective_output_mode)

        # è®¾ç½®ç›®æ ‡URLï¼ˆå¯é€‰å­—æ®µï¼Œå¯æ ¹æ®å®é™…æƒ…å†µæä¾›ï¼‰
        target_url = ""  # å¦‚æœæ²¡æœ‰ç‰¹å®šç›®æ ‡URLï¼Œä¿æŒä¸ºç©º

        # åˆå§‹åŒ– Planner å’Œ Reflector ä¸Šä¸‹æ–‡
        planner_context = PlannerContext(
            session_start_time=time.time(),
            initial_goal=goal,
            target_url=target_url,
            planning_history=[],
            rejected_strategies={},
            long_term_objectives=[]
        )

        reflector_context = ReflectorContext(
            session_start_time=time.time(),
            reflection_log=[],
            failure_patterns={},
            success_patterns={},
            active_hypotheses={}
        )
        try:
            planner.set_log_dir(log_dir)
            reflector.set_log_dir(log_dir)
        except Exception:
            pass
        global_mission_briefing = "ä»»åŠ¡çš„åˆå§‹ç›®æ ‡æ˜¯ï¼š" + goal # åˆå§‹åŒ–å…¨å±€ä»»åŠ¡ç®€æŠ¥

        # 1. è§„åˆ’ (Plan)
        console.print(Panel("è¿›å…¥è§„åˆ’é˜¶æ®µ...", title="Planner", style="bold blue"))

        causal_graph_summary = graph_manager.get_causal_graph_summary()
        initial_ops, call_metrics = await planner.plan(goal, causal_graph_summary)
        # å¢åŠ è®¡åˆ’æ­¥æ•°
        if call_metrics:
            call_metrics["plan_steps"] = call_metrics.get("plan_steps", 0) + 1
        else:
            call_metrics = {"plan_steps": 1}
        update_global_metrics(metrics, call_metrics)
        run_log.append({"event": "initial_plan", "data": initial_ops, "metrics": call_metrics, "timestamp": time.time()})
        try:
            await broker.emit("graph.changed", {"reason": "initial_plan_applied"}, op_id=os.path.basename(log_dir))
        except Exception:
            pass

        # HITL: åˆå§‹è®¡åˆ’å®¡æ‰¹
        if HUMAN_IN_THE_LOOP:
            op_id = os.path.basename(log_dir)
            
            # é€šçŸ¥å‰ç«¯æœ‰å¾…å®¡æ‰¹è¯·æ±‚
            try:
                await broker.emit("intervention.required", {"op_id": op_id, "type": "plan_approval"}, op_id=op_id)
            except Exception:
                pass
            
            # å¯åŠ¨ CLI äº¤äº’ä»»åŠ¡ (ä¸ Web ç«¯ç«æ€)
            cli_task = asyncio.create_task(handle_cli_approval(op_id, initial_ops))
                
            # é˜»å¡ç­‰å¾…å†³ç­–ï¼ˆä»»ä¸€ç«¯æäº¤å³å¯è§£é™¤é˜»å¡ï¼‰
            decision = await intervention_manager.request_approval(op_id, initial_ops)
            
            # æ¸…ç† CLI ä»»åŠ¡
            if not cli_task.done():
                cli_task.cancel()
                try:
                    await cli_task
                except asyncio.CancelledError:
                    pass
            
            action = decision.get("action")
            if action == "REJECT":
                console.print("[HITL] ç”¨æˆ·æ‹’ç»äº†åˆå§‹è®¡åˆ’ã€‚ä»»åŠ¡ç»ˆæ­¢ã€‚", style="bold red")
                return # é€€å‡ºä»»åŠ¡
            elif action == "MODIFY":
                initial_ops = decision.get("data", [])
                console.print("[HITL] ç”¨æˆ·ä¿®æ”¹äº†åˆå§‹è®¡åˆ’ï¼Œåº”ç”¨ä¿®æ”¹åçš„æ“ä½œã€‚", style="bold green")
            else:
                console.print("[HITL] ç”¨æˆ·æ‰¹å‡†äº†åˆå§‹è®¡åˆ’ã€‚", style="bold green")

        verified_ops = verify_and_handle_orphans(initial_ops, graph_manager, console)
        process_graph_commands(verified_ops, graph_manager)

        # è·å–æ¥ä¸‹æ¥å°†æ‰§è¡Œçš„ä»»åŠ¡ï¼Œç”¨äºé«˜äº®æ˜¾ç¤º
        next_executable_tasks = get_next_executable_subtask_batch(graph_manager)

        if effective_output_mode in ["default", "debug"]:
            console.print("åˆå§‹è®¡åˆ’å·²ç”Ÿæˆ:")
        if effective_output_mode in ["simple", "default", "debug"]:
            graph_manager.print_graph_structure(console, highlight_nodes=next_executable_tasks)
        if effective_output_mode in ["default", "debug"]:
            # è¾“å‡ºåˆå§‹å› æœé“¾å›¾è°±ç»“æ„ï¼Œè¾…åŠ©åç»­è°ƒè¯•ä¸å¯è§†åŒ–
            try:
                graph_manager.print_causal_graph(console, max_nodes=100)
            except Exception as e:
                console.print(Panel(f"æ‰“å°å› æœå›¾å¤±è´¥: {e}", title="å› æœå›¾é”™è¯¯", style="red"))
        run_log.append({"event": "initial_plan_generated", "plan": initial_ops, "timestamp": time.time()})

        # 3. æ‰§è¡Œ-åæ€-è§„åˆ’ å¾ªç¯
        completed_reflections = {} # æ”¶é›†å®Œæˆçš„åæ€è¾“å‡ºï¼ˆåŒ…å« intelligence_summaryï¼‰
        while True:
            # ==================================================
            # 1. è§„åˆ’é˜¶æ®µ (PLAN)
            # ==================================================
            if completed_reflections:
                if effective_output_mode in ["default", "debug"]:
                    console.print(Panel("æ±‡æ€»æƒ…æŠ¥ï¼ŒPlanner è¿›è¡Œæˆ˜ç•¥è§„åˆ’...", style="yellow"))

                intelligence_summary = _aggregate_intelligence(completed_reflections)

                refreshed_summary = graph_manager.get_full_graph_summary(detail_level=1)
                causal_graph_summary = graph_manager.get_causal_graph_summary()
                attack_path_summary = graph_manager.get_attack_path_summary()
                failure_patterns_summary = graph_manager.analyze_failure_patterns()

                plan_data, call_metrics = await planner.dynamic_plan(
                goal, refreshed_summary, intelligence_summary,
                causal_graph_summary, attack_path_summary, failure_patterns_summary, graph_manager,
                planner_context=planner_context
            )
                # è¾“å‡ºplannerçš„åŠ¨æ€è®¡åˆ’ç»“æœ
                if effective_output_mode in ["default", "debug"]:
                    console.print(Panel("Planner ç”Ÿæˆçš„åŠ¨æ€è®¡åˆ’:", title="åŠ¨æ€è®¡åˆ’", style="cyan"))
                    # æ¸…ç†JSONè¾“å‡ºï¼Œé˜²æ­¢åŒ…å«ç‰¹æ®Šå­—ç¬¦å¯¼è‡´Richè§£æé”™è¯¯
                    safe_plan_json = sanitize_for_rich(json.dumps(plan_data, indent=2, ensure_ascii=False))
                    console.print(Panel(safe_plan_json, style="cyan"))
                # å¢åŠ è®¡åˆ’æ­¥æ•°
                if call_metrics:
                    call_metrics["plan_steps"] = call_metrics.get("plan_steps", 0) + 1
                else:
                    call_metrics = {"plan_steps": 1}
                update_global_metrics(metrics, call_metrics)
                run_log.append({"event": "dynamic_plan", "data": plan_data, "metrics": call_metrics, "timestamp": time.time()})

                # æ£€æŸ¥Planneræ˜¯å¦å·²å®£å¸ƒä»»åŠ¡å®Œæˆ
                if plan_data.get("global_mission_accomplished"):
                    console.print(Panel("ğŸ‰ Plannerå·²å®£å¸ƒå…¨å±€ä»»åŠ¡ç›®æ ‡è¾¾æˆï¼ä»»åŠ¡ç»“æŸã€‚", title="[bold green]ä»»åŠ¡å®Œæˆ[/bold green]"))
                    metrics["success_info"] = {"found": True, "reason": "Global mission accomplished signal received from Planner."}
                    dynamic_ops = plan_data.get('graph_operations', [])
                    if dynamic_ops:
                        process_graph_commands(dynamic_ops, graph_manager)
                    break # é€€å‡ºä¸»å¾ªç¯

                # æ›´æ–°Plannerä¸Šä¸‹æ–‡çŠ¶æ€ï¼ˆæ–°å¢ï¼‰å¹¶ä¿å­˜å®Œæ•´LLMæç¤ºä¸å“åº”
                try:
                    # åŠ¨æ€è§„åˆ’çš„Promptå’ŒResponseä¸å†é€šè¿‡Plannerå±æ€§æŒä¹…åŒ–ï¼Œæ­¤å¤„ä¼ é€’None
                    last_prompt, last_response_text = None, None
                except Exception:
                    last_prompt, last_response_text = None, None
                planner_context = planner.update_planner_context_after_planning(
                    planner_context, plan_data, graph_manager, llm_prompt=last_prompt, llm_response=last_response_text
                )

                # æ£€æŸ¥å¹¶æ‰§è¡ŒPlannerä¸Šä¸‹æ–‡å‹ç¼©ï¼ˆå¦‚æœéœ€è¦ï¼‰
                await compress_planner_context_if_needed(planner_context, llm)

                dynamic_ops = plan_data.get('graph_operations', [])
                global_mission_briefing = plan_data.get('global_mission_briefing', global_mission_briefing)

                if dynamic_ops:
                    # HITL: åŠ¨æ€è®¡åˆ’å®¡æ‰¹
                    if HUMAN_IN_THE_LOOP:
                        op_id = os.path.basename(log_dir)
                        
                        try:
                            await broker.emit("intervention.required", {"op_id": op_id, "type": "plan_approval"}, op_id=op_id)
                        except Exception:
                            pass
                            
                        # å¯åŠ¨ CLI äº¤äº’ä»»åŠ¡
                        cli_task = asyncio.create_task(handle_cli_approval(op_id, dynamic_ops))
                        
                        decision = await intervention_manager.request_approval(op_id, dynamic_ops)
                        
                        if not cli_task.done():
                            cli_task.cancel()
                            try:
                                await cli_task
                            except asyncio.CancelledError:
                                pass
                        
                        action = decision.get("action")
                        if action == "REJECT":
                            console.print("[HITL] ç”¨æˆ·æ‹’ç»äº†åŠ¨æ€è®¡åˆ’ã€‚è·³è¿‡æœ¬æ¬¡æ›´æ–°ï¼ˆå¯èƒ½å¯¼è‡´åœæ»ï¼‰ã€‚", style="bold red")
                            dynamic_ops = [] # æ¸…ç©ºæ“ä½œï¼Œç»§ç»­å¾ªç¯
                        elif action == "MODIFY":
                            dynamic_ops = decision.get("data", [])
                            console.print("[HITL] ç”¨æˆ·ä¿®æ”¹äº†åŠ¨æ€è®¡åˆ’ã€‚", style="bold green")
                        else:
                            console.print("[HITL] ç”¨æˆ·æ‰¹å‡†äº†åŠ¨æ€è®¡åˆ’ã€‚", style="bold green")

                    if effective_output_mode in ["default", "debug"]:
                        console.print(Panel("Planner åŸºäºæƒ…æŠ¥åšå‡ºè§„åˆ’å†³ç­–ï¼Œå¼€å§‹æ›´æ–°...", style="yellow"))
                    verified_ops = verify_and_handle_orphans(dynamic_ops, graph_manager, console)
                    process_graph_commands(verified_ops, graph_manager)
                    try:
                        await broker.emit("graph.changed", {"reason": "dynamic_plan_applied"}, op_id=os.path.basename(log_dir))
                    except Exception:
                        pass
                    if effective_output_mode in ["default", "debug"]:
                        console.print("ä¸»ä»»åŠ¡å›¾æ›´æ–°å®Œæˆ:")
                    if effective_output_mode in ["simple", "default", "debug"]:
                        next_executable_tasks = get_next_executable_subtask_batch(graph_manager)
                        graph_manager.print_graph_structure(console, highlight_nodes=next_executable_tasks)
                    if effective_output_mode in ["default", "debug"]:
                        # åŒæ­¥è¾“å‡ºæ›´æ–°åçš„å› æœé“¾å›¾è°±ç»“æ„
                        try:
                            graph_manager.print_causal_graph(console, max_nodes=100)
                        except Exception as e:
                            console.print(Panel(f"æ‰“å°å› æœå›¾å¤±è´¥: {e}", title="å› æœå›¾é”™è¯¯", style="red"))

                # Periodically save logs after each full P-E-R cycle
                if effective_output_mode in ["default", "debug"]:
                    console.print(Panel("Saving log snapshot...", style="dim"))
                metrics["artifacts_found"] = len(graph_manager.causal_graph.nodes)
                # è®°å½•å› æœé“¾å›¾è°±èŠ‚ç‚¹
                metrics["causal_graph_nodes"] = list(graph_manager.causal_graph.nodes(data=True))
                save_logs(log_dir, metrics, run_log)

                completed_reflections = {}

# ==================================================
            # 2. æ‰§è¡Œé˜¶æ®µ (EXECUTE)
# ==================================================
            subtask_batch = get_next_executable_subtask_batch(graph_manager)

            if not subtask_batch and not completed_reflections:
                if not graph_manager.is_goal_achieved():
                    console.print(Panel("ä»»åŠ¡å…¨å±€åœæ»ï¼Œæ²¡æœ‰å¯æ‰§è¡Œçš„å­ä»»åŠ¡ï¼Œä½†ç›®æ ‡æœªè¾¾æˆã€‚å¼ºåˆ¶å¯åŠ¨æœ€ç»ˆè§„åˆ’...", title="å…¨å±€åœæ»", style="bold red"))
                    # å¼ºåˆ¶å¯åŠ¨ä¸€ä¸ªæœ€ç»ˆçš„é‡æ–°è§„åˆ’å‘¨æœŸ
                    completed_reflections['__FORCE_REPLAN__'] = {
                        "audit_result": {"status": "STALLED", "completion_check": "All tasks are blocked or completed, but the goal is not achieved."},
                        "key_findings": ["Global task execution has stalled."],
                        "validated_nodes": [],
                        "insight": {"type": "stall_analysis", "description": "The agent is stuck. A new high-level plan is required to find an alternative path."}
                    }
                    continue
                else:
                    # å¦‚æœç›®æ ‡å·²è¾¾æˆï¼Œåˆ™æ­£å¸¸ç»“æŸ
                    console.print(Panel("æ‰€æœ‰å­ä»»åŠ¡å·²å®Œæˆä¸”ç›®æ ‡å·²è¾¾æˆï¼Œä»»åŠ¡ç»“æŸã€‚", title="ä»»åŠ¡å®Œæˆ", style="bold green"))
                    break

            if not subtask_batch and not completed_reflections:
                 console.print(Panel("æœ€ç»ˆè§„åˆ’æœªèƒ½äº§ç”Ÿæ–°çš„å¯æ‰§è¡Œä»»åŠ¡ï¼Œä»£ç†å·²å°½åŠ›ï¼Œä»»åŠ¡ç»“æŸã€‚",
                                     title="æœ€ç»ˆå†³ç­–", style="bold red"))
                 break

            # Mark subtasks as in_progress visually
            for subtask_id in subtask_batch:
                graph_manager.update_node(subtask_id, {"status": "in_progress"})

            tasks = [
                asyncio.create_task(run_executor_cycle(goal, subtask_id, llm, graph_manager,
                    global_mission_briefing, log_dir=log_dir,
                    save_callback=lambda: save_logs(log_dir, metrics, run_log),
                    output_mode=effective_output_mode)) # Added output_mode
                for subtask_id in subtask_batch
            ]
            completed_results = await asyncio.gather(*tasks, return_exceptions=True)

# ==================================================
            # 3. åæ€ä¸åˆ†æ”¯çº§é‡æ–°è§„åˆ’ (REFLECT & BRANCH RE-PLAN)
# ==================================================
            branches_to_replan = [] # ç”¨äºå­˜å‚¨éœ€è¦ç«‹å³é‡æ–°è§„åˆ’çš„åˆ†æ”¯

            for i, result_or_exc in enumerate(completed_results):
                subtask_id = subtask_batch[i]
                try:
                    if isinstance(result_or_exc, Exception):
                        raise result_or_exc

                    _, result_status, cycle_metrics = result_or_exc
                    update_global_metrics(metrics, cycle_metrics)
                    run_log.append({"event": "executor_cycle_completed", "subtask_id": subtask_id,
                                    "status": result_status, "metrics": cycle_metrics, "timestamp": time.time()})

                    console.print(Panel(f"å­ä»»åŠ¡ {subtask_id} æ‰§è¡Œå®Œæ¯•ï¼ŒçŠ¶æ€: {result_status}ã€‚å¼€å§‹å³æ—¶åæ€...",
                                        title="Executor", style="bold blue"))

                    if not graph_manager.graph.has_node(subtask_id):
                        console.print(Panel(f"è·³è¿‡å·²åºŸå¼ƒ/åˆ é™¤çš„å­ä»»åŠ¡ {subtask_id} çš„åæ€é˜¶æ®µã€‚",
                                            title="è­¦å‘Š", style="yellow"))
                        continue

                    subtask_data = graph_manager.graph.nodes[subtask_id]
                    reflection_output = await reflector.reflect(
                        subtask_id=subtask_id,
                        subtask_data=subtask_data,
                        status=result_status,
                        execution_log=graph_manager.get_subtask_execution_log(subtask_id),
                        proposed_changes=subtask_data.get('proposed_changes', []),
                        staged_causal_nodes=subtask_data.get('staged_causal_nodes', []),
                        full_graph_summary=graph_manager.get_full_graph_summary(detail_level=1),
                        dependency_context=graph_manager.build_prompt_context(subtask_id).get("dependencies", []),
                        graph_manager=graph_manager,
                        reflector_context=reflector_context
                    )

                    update_global_metrics(metrics, reflection_output.get('metrics'))
                    run_log.append({"event": "reflection_completed", "subtask_id": subtask_id, "data": reflection_output, "metrics": reflection_output.get('metrics'), "timestamp": time.time()})

                    # æ›´æ–°Reflectorä¸Šä¸‹æ–‡çŠ¶æ€ï¼ˆæ–°å¢ï¼‰
                    reflector_context = update_reflector_context_after_reflection(
                        reflector_context, reflection_output, subtask_id, result_status, graph_manager
                    )

                    # æ£€æŸ¥å¹¶æ‰§è¡ŒReflectorä¸Šä¸‹æ–‡å‹ç¼©ï¼ˆå¦‚æœéœ€è¦ï¼‰
                    await compress_reflector_context_if_needed(reflector_context, llm)

                    # è¾“å‡ºreflection_output
                    if effective_output_mode in ["default", "debug"]:
                        console.print(Panel("Reflector è¾“å‡º:", title=f"å­ä»»åŠ¡ {subtask_id} åæ€ç»“æœ", style="cyan"))
                        # åˆ›å»ºä¸€ä¸ªç”¨äºæ˜¾ç¤ºçš„å‰¯æœ¬ï¼Œç§»é™¤ä¸å¿…è¦çš„å·¨å¤§å­—æ®µ
                        display_output = {k: v for k, v in reflection_output.items() if k not in ['llm_reflection_prompt', 'llm_reflection_response']}
                        # æ¸…ç†JSONè¾“å‡ºï¼Œé˜²æ­¢åŒ…å«ç‰¹æ®Šå­—ç¬¦å¯¼è‡´Richè§£æé”™è¯¯
                        safe_reflection_json = sanitize_for_rich(json.dumps(display_output, indent=2, ensure_ascii=False))
                        console.print(Panel(safe_reflection_json, style="cyan"))
                    # æ£€æŸ¥æ˜¯å¦è§¦å‘åˆ†æ”¯çº§é‡æ–°è§„åˆ’
                    audit_result = reflection_output.get("audit_result", {})
                    if audit_result.get("is_strategic_failure"):
                        console.print(Panel(f"æ£€æµ‹åˆ°å­ä»»åŠ¡ {subtask_id} çš„æˆ˜ç•¥æ€§å¤±è´¥ã€‚è§¦å‘è¯¥åˆ†æ”¯çš„å³æ—¶é‡æ–°è§„åˆ’...", title="ğŸš¨ åˆ†æ”¯é‡æ–°è§„åˆ’", style="bold red"))
                        branches_to_replan.append((subtask_id, reflection_output))
                    else:
                        # åªæœ‰éæˆ˜ç•¥æ€§å¤±è´¥æ‰è¿›å…¥æ­£å¸¸çš„å…¨å±€è§„åˆ’æµç¨‹
                        completed_reflections[subtask_id] = reflection_output

                    causal_graph_updates = reflection_output.get("causal_graph_updates", {})
                    if causal_graph_updates:
                        validated_updates = validate_causal_graph_updates(causal_graph_updates,
                                                                          graph_manager, subtask_id=subtask_id)
                        process_causal_graph_commands(validated_updates, graph_manager)
                        # Added causal graph print for simple mode requirement
                        if effective_output_mode in ["simple", "default", "debug"]:
                            try:
                                console.print(Panel(f"å­ä»»åŠ¡ {subtask_id} å› æœå›¾æ›´æ–°:", title="å› æœå›¾æ›´æ–°", style="green"))
                                graph_manager.print_causal_graph(console, max_nodes=100)
                            except Exception as e:
                                console.print(Panel(f"æ‰“å°å› æœå›¾å¤±è´¥: {e}", title="å› æœå›¾é”™è¯¯", style="red"))

                    # å¤„ç†å…³é”®äº‹å® (key_facts)
                    key_facts = reflection_output.get("key_facts", [])
                    if key_facts: # Key facts should always be printed, even in simple mode
                        console.print(f"ğŸ”‘ Reflector æç‚¼å‡º {len(key_facts)} ä¸ªå…³é”®äº‹å®", style="bold cyan")
                        for fact in key_facts:
                            if isinstance(fact, str) and fact.strip():
                                fact_id = graph_manager.add_key_fact(fact.strip())
                                console.print(f"  âœ“ å…³é”®äº‹å®å·²è®°å½•: {fact[:80]}{'...' if len(fact) > 80 else ''}", style="cyan")

                    subtask_audit_status = audit_result.get("status", "FAILED")
                    # ç»Ÿä¸€è½¬æ¢ä¸ºå°å†™è¿›è¡Œæ¯”è¾ƒ
                    status_lower = str(subtask_audit_status).lower()
                    
                    # åˆ¤æ–­çŠ¶æ€ï¼šcompleted, incomplete, æˆ– failed
                    if status_lower in ["completed", "pass", "goal_achieved"]:
                        new_status = "completed"
                    elif status_lower == "incomplete":
                        new_status = "pending"
                    else:
                        new_status = "failed"

                    graph_manager.update_node(subtask_id, {"status": new_status,
                                                           "summary": reflection_output.get("audit_result", {}).get("completion_check")})

                    # å­ä»»åŠ¡ç»“æŸåæ¸…ç†æš‚å­˜èŠ‚ç‚¹ï¼ˆcompleted æˆ– failed çŠ¶æ€éƒ½éœ€è¦æ¸…ç†ï¼‰
                    if new_status in ["completed", "failed"]:
                        graph_manager.clear_staged_causal_nodes(subtask_id)
                    # å¤„ç†å› æœå›¾è°±èŠ‚ç‚¹ï¼ˆæ¥è‡ªReflectorçš„éªŒè¯èŠ‚ç‚¹ï¼‰
                    # new_nodes_for_exploration = reflection_output.get("causal_graph_updates", {}).get("nodes", [])
                    # if new_nodes_for_exploration:
                    #     graph_manager.update_exploration_state(new_nodes_for_exploration)

                    # ä¹Ÿå¤„ç†validated_nodeså­—æ®µï¼ˆæ–°æ•°æ®ç»“æ„ï¼‰
                    # validated_nodes = reflection_output.get('validated_nodes', [])
                    # if validated_nodes:
                    #     graph_manager.update_exploration_state(validated_nodes)

                    # å°†åæ€æŠ¥å‘Šä¿å­˜åˆ°Plannerä¸Šä¸‹æ–‡ï¼Œç”¨äºä¸‹ä¸€æ¬¡è§„åˆ’ï¼ˆæ–°å¢ï¼‰
                    planner_context.latest_reflection_report = reflection_output

                except Exception as e:
                    import traceback
                    error_message = str(e)
                    console.print(Panel(f"å¤„ç†å­ä»»åŠ¡ {subtask_id} ç»“æœæ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {error_message}\n{traceback.format_exc()}", title="é”™è¯¯", style="bold red"))
                    graph_manager.update_node(subtask_id, {'status': 'completed_error', 'summary': f"Critical error during reflection: {error_message}"})
                    # å³ä½¿å‡ºé”™ä¹Ÿæ¸…ç†æš‚å­˜èŠ‚ç‚¹
                    graph_manager.clear_staged_causal_nodes(subtask_id)

            # å¦‚æœæœ‰éœ€è¦ç«‹å³é‡æ–°è§„åˆ’çš„åˆ†æ”¯ï¼Œåˆ™æ‰§è¡Œ
            if branches_to_replan:
                for subtask_id, reflection in branches_to_replan:
                    if effective_output_mode in ["default", "debug"]:
                        console.print(Panel(f"æ­£åœ¨ä¸ºå¤±è´¥çš„åˆ†æ”¯ {subtask_id} ç”Ÿæˆæ–°è®¡åˆ’...", title="Planner - åˆ†æ”¯å†ç”Ÿ", style="purple"))
                    failure_reason = reflection.get("audit_result", {}).get("completion_check", "æœªæä¾›å…·ä½“å¤±è´¥åŸå› ã€‚")

                    # è°ƒç”¨æ–°çš„åˆ†æ”¯é‡æ–°è§„åˆ’æ–¹æ³• (ä¸‹ä¸€æ­¥å®ç°)
                    branch_replan_ops, branch_replan_metrics = await planner.regenerate_branch_plan(
                        goal=goal,
                        graph_manager=graph_manager,
                        failed_branch_root_id=subtask_id,
                        failure_reason=failure_reason
                    )

                    update_global_metrics(metrics, branch_replan_metrics)
                    run_log.append({"event": "branch_replan", "subtask_id": subtask_id, "data": branch_replan_ops, "metrics": branch_replan_metrics, "timestamp": time.time()})

                    if branch_replan_ops:
                        if effective_output_mode in ["default", "debug"]:
                            console.print(f"åº”ç”¨ä¸ºåˆ†æ”¯ {subtask_id} ç”Ÿæˆçš„æ–°è®¡åˆ’...")
                        verified_ops = verify_and_handle_orphans(branch_replan_ops, graph_manager, console)
                        process_graph_commands(verified_ops, graph_manager)
                        try:
                            await broker.emit("graph.changed", {"reason": "branch_replan_applied"}, op_id=os.path.basename(log_dir))
                        except Exception:
                            pass
                        if effective_output_mode in ["simple", "default", "debug"]:
                            next_executable_tasks = get_next_executable_subtask_batch(graph_manager)
                            graph_manager.print_graph_structure(console, highlight_nodes=next_executable_tasks)
                        if effective_output_mode in ["default", "debug"]:
                            # è¾“å‡ºåˆ†æ”¯å†è§„åˆ’åå› æœé“¾å›¾è°±ç»“æ„
                            try:
                                graph_manager.print_causal_graph(console, max_nodes=100)
                            except Exception as e:
                                console.print(Panel(f"æ‰“å°å› æœå›¾å¤±è´¥: {e}", title="å› æœå›¾é”™è¯¯", style="red"))

                # æ¸…ç©º completed_reflections ä»¥é˜²æ­¢å…¨å±€è§„åˆ’å™¨ä¸åˆ†æ”¯è§„åˆ’å†²çª
                completed_reflections = {}

            # Save logs after each batch of executor cycles and reflections
            if effective_output_mode in ["default", "debug"]:
                console.print(Panel("Saving log snapshot after batch processing...", style="dim"))
            metrics["artifacts_found"] = len(graph_manager.causal_graph.nodes)
            # è®°å½•å› æœé“¾å›¾è°±èŠ‚ç‚¹
            metrics["causal_graph_nodes"] = list(graph_manager.causal_graph.nodes(data=True))
            save_logs(log_dir, metrics, run_log)

        # 4. æœ€ç»ˆå½’æ¡£ (åœ¨ä¸»å¾ªç¯ç»“æŸåæ‰§è¡Œ)
        console.print(Panel("ä»»åŠ¡å®Œæˆï¼Œå¼€å§‹å…¨å±€åæ€ä¸å½’æ¡£...", title="å…¨å±€åæ€", style="bold green"))
        global_reflection = await reflector.reflect_global(graph_manager)

        global_reflection_metrics = global_reflection.get('metrics')
        # å¢åŠ å…¨å±€åæ€æ­¥æ•°
        if global_reflection_metrics:
            global_reflection_metrics["reflect_steps"] = global_reflection_metrics.get("reflect_steps", 0) + 1
        else:
            global_reflection_metrics = {"reflect_steps": 1}
        update_global_metrics(metrics, global_reflection_metrics)
        run_log.append({"event": "global_reflection_completed", "data": global_reflection, "metrics": global_reflection_metrics, "timestamp": time.time()})

        # If web server is running, keep the process alive to allow for inspection.
        if args.web:
            console.print(Panel("ä»»åŠ¡æ‰§è¡Œå®Œæˆã€‚WebæœåŠ¡ä»åœ¨è¿è¡Œä¸­ï¼ŒæŒ‰ [Ctrl+C] é€€å‡ºã€‚", title="ä»»åŠ¡ç»“æŸ", style="bold green"))
            while True:
                await asyncio.sleep(3600) # Sleep for a long time

    finally:
        # Ensure final logs are saved no matter what
        metrics["artifacts_found"] = len(graph_manager.causal_graph.nodes)
        # è®°å½•å› æœé“¾å›¾è°±èŠ‚ç‚¹
        metrics["causal_graph_nodes"] = list(graph_manager.causal_graph.nodes(data=True))
        save_logs(log_dir, metrics, run_log, final_save=True)

        # Clean up any remaining halt signals
        if task_id:
            halt_file = os.path.join(tempfile.gettempdir(), f"{task_id}.halt")
            if os.path.exists(halt_file):
                try:
                    os.remove(halt_file)
                    console.print(f"æ¸…ç†æ®‹ç•™çš„ç»ˆæ­¢ä¿¡å·æ–‡ä»¶: {halt_file}", style="dim")
                except OSError as e:
                    console.print(f"æ¸…ç†ç»ˆæ­¢ä¿¡å·æ–‡ä»¶å¤±è´¥: {e}", style="red")
        await close_async_sessions()

if __name__ == "__main__":
    asyncio.run(main())
