#!/usr/bin/env python3
"""
ç»Ÿä¸€æç¤ºè¯ç®¡ç†å™¨ (Centralized Prompt Manager)
"""

import os
import json
from typing import Dict, Any, List, Optional
from jinja2 import Environment, FileSystemLoader, select_autoescape

from core.prompts.renderers import (
    render_causal_graph,
    render_failure_patterns,
    render_key_facts,
    render_dependencies_summary,
)


from conf.config import SCENARIO_MODE

class PromptManager:
    """
    ç»Ÿä¸€çš„æç¤ºè¯ç®¡ç†å™¨
    
    è´Ÿè´£æ‰€æœ‰è§’è‰²(Planner, Executor, Reflector)çš„Promptç”Ÿæˆä¸ä¸Šä¸‹æ–‡æ¸²æŸ“ã€‚
    ä½¿ç”¨Jinja2æ¨¡æ¿å¼•æ“ç¡®ä¿æç¤ºè¯çš„ä¸€è‡´æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚
    """

    def __init__(self):
        """åˆå§‹åŒ–æç¤ºè¯ç®¡ç†å™¨,åŠ è½½Jinja2æ¨¡æ¿"""
        # è·å–æ¨¡æ¿ç›®å½•è·¯å¾„
        template_dir = os.path.join(os.path.dirname(__file__), "templates")

        # åˆ›å»ºJinja2ç¯å¢ƒ
        self.env = Environment(
            loader=FileSystemLoader(template_dir),
            autoescape=select_autoescape(["html", "xml"]),
            trim_blocks=True,
            lstrip_blocks=True,
        )

        self.planner_template = self.env.get_template("planner_template.jinja2")
        self.executor_template = self.env.get_template("executor_template.jinja2")
        self.reflector_template = self.env.get_template("reflector_template.jinja2")
        self.branch_replan_template = self.env.get_template("branch_replan_template.jinja2")

    def build_planner_prompt(
        self, goal: str, context: Dict[str, Any], is_dynamic: bool = False, planner_context: Optional[Any] = None
    ) -> str:
        """
        æ„å»º Planner æç¤ºè¯

        Args:
            goal: ç”¨æˆ·çš„é«˜çº§ç›®æ ‡
            context: ä¸Šä¸‹æ–‡æ•°æ®å­—å…¸
            is_dynamic: æ˜¯å¦ä¸ºåŠ¨æ€è§„åˆ’
            planner_context: è§„åˆ’ä¸Šä¸‹æ–‡å¯¹è±¡

        Returns:
            æ ¼å¼åŒ–åçš„æç¤ºè¯å­—ç¬¦ä¸²
        """
        # 1. æ¸²æŸ“é€šç”¨ç»„ä»¶
        failure_text = render_failure_patterns(context.get("failure_patterns"))

        # 2. ç»„è£…è¾“å…¥å˜é‡ - ç›´æ¥ä¼ é€’æ•°æ®ç»™æ¨¡æ¿
        input_variables = {
            "goal": goal,
            "causal_graph_summary": context.get("causal_graph_summary", "å› æœé“¾å›¾è°±ä¸ºç©ºã€‚"),
            "failure_patterns": failure_text,
            "failed_tasks_summary": context.get("failed_tasks_summary", ""),
            "retrieved_experience": context.get("retrieved_experience", ""),
            # æ§åˆ¶ CTF åœºæ™¯ä¼˜åŒ– - åŸºäºå…¨å±€é…ç½®
            "use_ctf_optimizations": SCENARIO_MODE == "ctf",
        }

        # 3. åŠ¨æ€è§„åˆ’ç‰¹æœ‰éƒ¨åˆ†
        if is_dynamic:
            input_variables["dynamic_context"] = {
                "graph_summary": context.get("graph_summary", ""),
                "intelligence_summary": json.dumps(
                    context.get("intelligence_summary", {}), indent=2, ensure_ascii=False
                ),
            }

        # 4. è§„åˆ’ä¸Šä¸‹æ–‡
        if planner_context:
            input_variables["planning_context"] = self._render_planning_context_section(planner_context)

        return self.planner_template.render(**input_variables)

    def build_executor_prompt(
        self, main_goal: str, subtask: Dict[str, Any], context: Dict[str, Any], global_mission_briefing: str = ""
    ) -> str:
        """
        æ„å»º Executor æç¤ºè¯

        Args:
            main_goal: æ ¸å¿ƒæ€»ç›®æ ‡
            subtask: å½“å‰å­ä»»åŠ¡æ•°æ®
            context: ä¸Šä¸‹æ–‡æ•°æ®å­—å…¸
            global_mission_briefing: å…¨å±€ä»»åŠ¡ç®€æŠ¥

        Returns:
            æ ¼å¼åŒ–åçš„æç¤ºè¯å­—ç¬¦ä¸²
        """
        # 1. æ¸²æŸ“å…³é”®äº‹å®
        key_facts_text = render_key_facts(context.get("key_facts", []))

        # 2. æ¸²æŸ“å› æœå›¾(ç›¸å…³ä¸Šä¸‹æ–‡æ¨¡å¼)
        causal_graph_text = render_causal_graph(context.get("causal_context", {}), mode="relevant")

        # 3. æ¸²æŸ“ä¾èµ–æ‘˜è¦
        dependency_text = render_dependencies_summary(context.get("dependencies", []))

        # 4. å…¨å±€å› æœé“¾å›¾è°±æ‘˜è¦
        full_graph_section = ""
        global_causal_graph_summary = context.get("causal_graph_summary")
        if global_causal_graph_summary and global_causal_graph_summary != "å› æœé“¾å›¾è°±ä¸ºç©ºã€‚":
            full_graph_section = f"""
              ### ğŸ—ºï¸ å…¨å±€å› æœé“¾å›¾è°±æ‘˜è¦ (Global Causal Graph Summary)
              {global_causal_graph_summary}
            """

        # 5. ç”Ÿæˆå·¥å…·éƒ¨åˆ†
        tools_section = self._generate_tools_section()

        # 6. æ¸²æŸ“å¤±è´¥æ¨¡å¼
        failure_patterns_data = context.get("causal_context", {}).get("failure_patterns", {})
        failure_patterns_text = render_failure_patterns(failure_patterns_data)

        # 7. ç»„è£…è¾“å…¥å˜é‡
        input_variables = {
            "main_goal": main_goal,
            "global_mission_briefing": global_mission_briefing,
            "subtask_id": subtask.get("id", "N/A"),
            "subtask_goal": subtask.get("description", "N/A"),
            "completion_criteria": subtask.get("completion_criteria", "N/A"),
            "key_facts": key_facts_text,
            "full_graph_section": full_graph_section,
            "causal_graph_summary": context.get("causal_graph_summary", "å› æœé“¾å›¾è°±ä¸ºç©ºã€‚"),
            "dependency_context": dependency_text,
            "tools_section": tools_section,
            "failure_patterns": failure_patterns_text,
            "active_constraints": context.get("active_constraints", []),
        }

        return self.executor_template.render(**input_variables)

    def build_reflector_prompt(
        self,
        subtask: Dict[str, Any],
        status: str,
        execution_log: str,
        staged_causal_nodes: List[Dict],
        context: Dict[str, Any],
        reflector_context: Optional[Any] = None,
    ) -> str:
        """
        æ„å»º Reflector æç¤ºè¯

        Args:
            subtask: å­ä»»åŠ¡æ•°æ®
            status: æ‰§è¡ŒçŠ¶æ€
            execution_log: æ‰§è¡Œæ—¥å¿—
            staged_causal_nodes: æš‚å­˜çš„å› æœèŠ‚ç‚¹
            context: ä¸Šä¸‹æ–‡æ•°æ®å­—å…¸
            reflector_context: åæ€ä¸Šä¸‹æ–‡å¯¹è±¡

        Returns:
            æ ¼å¼åŒ–åçš„æç¤ºè¯å­—ç¬¦ä¸²
        """
        # 1. åºåˆ—åŒ–èŠ‚ç‚¹æ•°æ®
        staged_causal_nodes_json = json.dumps(staged_causal_nodes, indent=2, ensure_ascii=False)

        # 2. æ¸²æŸ“å¤±è´¥æ¨¡å¼
        failure_patterns_text = render_failure_patterns(context.get("failure_patterns"))

        # 3. è·å–å› æœå›¾æ‘˜è¦æ•°æ®
        causal_graph_summary = context.get("causal_graph_summary", "å› æœé“¾å›¾è°±ä¸ºç©ºã€‚")

        # 4. å¤„ç†ç»ˆæ­¢ä¿¡æ¯
        termination_reason = "N/A"
        executed_steps = "N/A"

        dependency_context = context.get("dependency_context", [])
        if dependency_context and isinstance(dependency_context, list):
            # æŸ¥æ‰¾å½’ä¸€åŒ–çš„ç»ˆæ­¢ä¿¡æ¯
            normalized_items = [
                item for item in dependency_context if isinstance(item, dict) and item.get("source") == "normalized"
            ]
            if normalized_items:
                item = normalized_items[0]
                termination_reason = item.get("termination_reason", "N/A")
                executed_steps = str(item.get("executed_steps", "N/A"))

        # 5. ç»„è£…è¾“å…¥å˜é‡
        input_variables = {
            "subtask_goal": subtask.get("description", subtask.get("id", "N/A")),
            "status": status,
            "completion_criteria": subtask.get("completion_criteria", "N/A"),
            "execution_log": execution_log,
            "staged_causal_nodes_json": staged_causal_nodes_json,
            "termination_reason": termination_reason,
            "executed_steps": executed_steps,
            "causal_graph_summary": causal_graph_summary,
            "dependency_context": json.dumps(dependency_context, indent=2, ensure_ascii=False)
            if dependency_context
            else "[]",
            "failure_patterns": failure_patterns_text,
        }

        # 6. åæ€ä¸Šä¸‹æ–‡
        if reflector_context:
            input_variables["reflection_context"] = self._render_reflection_context_section(reflector_context)

        return self.reflector_template.render(**input_variables)

    def _generate_tools_section(self) -> str:
        """
        ç”Ÿæˆå·¥å…·éƒ¨åˆ†çš„æç¤ºè¯ã€‚
        åˆ—å‡ºæ‰€æœ‰å¯ç”¨å·¥å…·ï¼ŒæŒ‰åç§°æ’åºã€‚

        Returns:
            æ ¼å¼åŒ–çš„å·¥å…·æ–‡æ¡£å­—ç¬¦ä¸²
        """
        from core.tool_manager import get_dynamic_tools_documentation

        tools_documentation = get_dynamic_tools_documentation()
        
        tools_section = f"""
{tools_documentation}

**é‡è¦**:
- **ä¼˜å…ˆä½¿ç”¨ä¸“ç”¨å·¥å…·**: å¦‚æœå­˜åœ¨é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„ä¸“ç”¨å·¥å…·(å¦‚ `dirsearch_scan` ç”¨äºç›®å½•æ‰«æ,`sqlmap_scan` ç”¨äºSQLæ³¨å…¥),**å¿…é¡»**ä¼˜å…ˆä½¿ç”¨è¯¥å·¥å…·,è€Œä¸æ˜¯é€šç”¨çš„ `shell_exec`ã€‚
- **ä½¿ç”¨ `extra_args`**: å½“ä¸“ç”¨å·¥å…·ç¼ºå°‘æŸä¸ªå‘½ä»¤è¡Œå‚æ•°æ—¶,åº”ä½¿ç”¨ `extra_args` å­—æ®µæ¥ä¼ é€’è¿™äº›é¢å¤–å‚æ•°ã€‚
- **å·¥å…·è°ƒç”¨è¯­æ³•**: å·¥å…·è°ƒç”¨å¿…é¡»åœ¨ `execution_operations` çš„ `action` å­—æ®µä¸­å®šä¹‰,æ ¼å¼ä¸º `{{"tool": "å·¥å…·åç§°", "params": {{...}} }}`ã€‚
- **ä¸¥æ ¼åŒ¹é…**: å·¥å…·åç§°å’Œå‚æ•°å¿…é¡»å®Œå…¨åŒ¹é…å¯ç”¨å·¥å…·åˆ—è¡¨ä¸­çš„å®šä¹‰ã€‚
- **RAGå¤±è´¥å‡çº§**: çŸ¥è¯†æ£€ç´¢å¤šæ¬¡æ— æ•ˆä¸”é™·å…¥åƒµå±€æ—¶,**å¿…é¡»**è°ƒç”¨ `expert_analysis`,å¹¶é™„ä¸Šæ£€ç´¢è¯ã€æºç±»å‹ã€å…³é”®è¯æ®ä¸é”™è¯¯æ‘˜è¦ä½œä¸ºä¸Šä¸‹æ–‡ã€‚
"""

        return tools_section

    def _render_planning_context_section(self, planner_context) -> str:
        """
        ç”Ÿæˆè§„åˆ’ä¸Šä¸‹æ–‡æ‘˜è¦éƒ¨åˆ†

        Args:
            planner_context: è§„åˆ’ä¸Šä¸‹æ–‡å¯¹è±¡

        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡æ‘˜è¦å­—ç¬¦ä¸²
        """
        from datetime import datetime

        # è¿™é‡Œå¯ä»¥å¤ç”¨ planner.py ä¸­çš„é€»è¾‘
        # ä¸ºç®€åŒ–ç¤ºä¾‹,è¿™é‡Œåªæä¾›åŸºæœ¬å®ç°
        summary = []

        if hasattr(planner_context, "planning_history") and planner_context.planning_history:
            summary.append("## å†å²è§„åˆ’ä¸Šä¸‹æ–‡")
            summary.append("\n### è§„åˆ’å†å²æ‘˜è¦")
            for attempt in planner_context.planning_history[-3:]:
                timestamp = datetime.fromtimestamp(attempt.timestamp).strftime("%H:%M:%S")
                summary.append(f"- {timestamp}: ç­–ç•¥ã€Œ{attempt.strategy}ã€â†’ {attempt.outcome_summary}")

        return "\n".join(summary)

    def _render_reflection_context_section(self, reflector_context) -> str:
        """
        ç”Ÿæˆåæ€ä¸Šä¸‹æ–‡æ‘˜è¦éƒ¨åˆ†

        Args:
            reflector_context: åæ€ä¸Šä¸‹æ–‡å¯¹è±¡

        Returns:
            æ ¼å¼åŒ–çš„åæ€ä¸Šä¸‹æ–‡æ‘˜è¦å­—ç¬¦ä¸²
        """
        # ä¸ºç®€åŒ–ç¤ºä¾‹,è¿™é‡Œåªæä¾›åŸºæœ¬å®ç°
        summary = []

        if hasattr(reflector_context, "reflection_log") and reflector_context.reflection_log:
            summary.append("## å†å²åæ€ä¸Šä¸‹æ–‡")
            summary.append("\n### ç›¸å…³å†å²åæ€")
            for reflection in reflector_context.reflection_log[-3:]:
                summary.append(f"- {reflection.subtask_id}: {reflection.key_insight}")

        return "\n".join(summary)

    def build_branch_replan_prompt(self, original_branch_goal: str, failure_reason: str, dead_end_tasks: list) -> str:
        """
        æ„å»ºåˆ†æ”¯é‡è§„åˆ’æç¤ºè¯

        Args:
            original_branch_goal: å¤±è´¥çš„åˆ†æ”¯ç›®æ ‡
            failure_reason: å¤±è´¥åŸå› æè¿°
            dead_end_tasks: éœ€è¦åºŸå¼ƒçš„ä»»åŠ¡IDåˆ—è¡¨

        Returns:
            æ ¼å¼åŒ–åçš„åˆ†æ”¯é‡è§„åˆ’æç¤ºè¯å­—ç¬¦ä¸²
        """
        # ç»„è£…è¾“å…¥å˜é‡
        input_variables = {
            "original_branch_goal": original_branch_goal,
            "failure_reason": failure_reason,
            "dead_end_tasks": json.dumps(dead_end_tasks, indent=2, ensure_ascii=False),
        }

        return self.branch_replan_template.render(**input_variables)
